{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de3912eb-612a-499e-9c4e-edee06488a45",
   "metadata": {},
   "source": [
    "# Multi-GPU Backtest the strategies\n",
    "\n",
    "Use an LLM to go through and predict the buy/ sell/ hold recommendation for the company for the given date. Steps needed:\n",
    "\n",
    "1. Load the LLM - use DeepSeek R1 Qwen model at 7B parameters first and try the quantised models next\n",
    "2. Step through each data and each financial statement to get a result\n",
    "3. Log the results in a file and save to S3 (will need a logging file to save to S3 and resume in case of kernel crash)\n",
    "4. Need a backtesting framework to apply the results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d93b98-69cc-4462-a0f4-a17f2f95dd3f",
   "metadata": {},
   "source": [
    "## Load libraries needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1d33ab5-af9c-4fdc-9f1c-6a210084e202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running: micromamba install pytorch-gpu torchvision torchaudio pytorch-cuda=12.1 -c pytorch -c nvidia --yes --quiet --log-level=error\n",
      "\n",
      "Note: Packages not from Bloomberg channels are not vetted by Bloomberg.\n",
      "\u001b[93mPlease restart the Jupyter kernel if you run into any issues after installing or updating packages via %package.\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%package install pytorch-gpu torchvision torchaudio pytorch-cuda=12.1 -c pytorch -c nvidia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3af882af-086b-45c8-a773-215a83e2a864",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "from s3fs import S3FileSystem\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from huggingface_hub import login\n",
    "import torch\n",
    "from accelerate import Accelerator\n",
    "\n",
    "import pandas as pd\n",
    "from IPython.display import Markdown, display\n",
    "from ipywidgets import IntProgress, Label, HBox\n",
    "\n",
    "from helper import get_s3_folder\n",
    "import s3Helpers\n",
    "import company_data\n",
    "import prompts\n",
    "from s3Helpers import S3ModelHelper, Logger\n",
    "from prompts import SYSTEM_PROMPTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4fb4ed3-be43-40fa-bd65-13d7588c9c3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'prompts' from '/project/prompts.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(company_data)\n",
    "importlib.reload(s3Helpers)\n",
    "importlib.reload(prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09b47836-92ef-4a05-99b8-7bbcad4c9acc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb94ecb-4b18-41c5-8849-696b395f4de1",
   "metadata": {},
   "source": [
    "## Load the LLM\n",
    "\n",
    "Models to test:\n",
    "- Qwen (Qwen/Qwen2.5-7B-Instruct)\n",
    "- Llama (meta-llama/Llama-3.2-7B-Instruct)\n",
    "- DeepSeek (deepseek-ai/DeepSeek-R1-Distill-Qwen-14B)\n",
    "- DeepSeek Quantized (deepseek-ai/DeepSeek-R1-Distill-Qwen-32B) quantized to 4 bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd948d2f-1791-4313-bedc-f9ed31aa63a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log into Huggingface\n",
    "\n",
    "with open('pass.txt') as p:\n",
    "    hf_login = p.read()\n",
    "    \n",
    "hf_login = hf_login[hf_login.find('=')+1:hf_login.find('\\n')]\n",
    "login(hf_login, add_to_git_credential=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4aaea478-b1ed-420b-bd8f-0851b1c6e3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Quantization \n",
    "quant_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    bnb_4bit_quant_type=\"nf4\"\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab36cbb0-6764-4b22-b83d-7ff24b4aa054",
   "metadata": {},
   "outputs": [],
   "source": [
    "accelerator = Accelerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c2bb562-aec7-44a3-87a7-c509839c6dc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "305d17f80e9b4169bf764a54ba6c8152",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/664 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8532c8f47bd2449ca1210340f7e046c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/64.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ac4288fa8844f7ab9df1dd87b25451f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "122b61c4de6b4e778e9074ad843fa6b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-000008.safetensors:   0%|          | 0.00/8.79G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe3743afcab94975811d90433faf98ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-000008.safetensors:   0%|          | 0.00/8.78G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "445c649256e24111b5c3960e870ecbc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-000008.safetensors:   0%|          | 0.00/8.78G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65d05fc656d3440a9585563503254f01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-000008.safetensors:   0%|          | 0.00/8.78G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "913074fdaca44124ae2869f2b73381f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00005-of-000008.safetensors:   0%|          | 0.00/8.78G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58eb5fc13da74c3fa1892385bc62e314",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00006-of-000008.safetensors:   0%|          | 0.00/8.78G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba2da2302bb745b5b4ba4113173e4a8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00007-of-000008.safetensors:   0%|          | 0.00/8.78G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e766eab7cbd1450b9c1072598cdac51b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00008-of-000008.safetensors:   0%|          | 0.00/4.07G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73526d3035164932945533fa9a881320",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd1373286ae94492aa7e623a29359276",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/181 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f744ee0c4ba04075be495954d3509c7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/3.07k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c522b2c885964517bb641e659ff9eae2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/7.03M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory footprint: 18.7 GB\n"
     ]
    }
   ],
   "source": [
    "# Flag to download from Huggingface again or use stored model\n",
    "USE_HF = True\n",
    "USE_QUANTIZATION = True\n",
    "\n",
    "model_id = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-32B\"\n",
    "model_id_s3 = 'deepseek32'\n",
    "\n",
    "\n",
    "if USE_HF:\n",
    "    \n",
    "    if USE_QUANTIZATION:\n",
    "        model = AutoModelForCausalLM.from_pretrained(model_id, device_map={\"\":accelerator.process_index}, quantization_config=quant_config)\n",
    "    else:\n",
    "        model = AutoModelForCausalLM.from_pretrained(model_id, device_map={\"\":accelerator.process_index}, torch_dtype=torch.bfloat16)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "else:\n",
    "    # load the pre-saved model from S3\n",
    "    model_helper = s3Helpers.S3ModelHelper(s3_sub_folder='tmp/fs')\n",
    "    model = model_helper.load_model(model_id_s3, accelerator)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "    model_helper.clear_folder(model_id_s3)\n",
    "\n",
    "print(f\"Memory footprint: {model.get_memory_footprint() / 1e9:,.1f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6029e0fb-a198-4dea-b42b-d506c783a7f4",
   "metadata": {},
   "source": [
    "## Load Financial PIT dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eaa01423-1a10-4b83-a25c-ebf18b932470",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load from S3 using the helper file\n",
    "filename = 'data_annual_pit_indu.json' #'data_quarterly_pit_indu.json'\n",
    "sec_helper = company_data.SecurityData('tmp/fs',filename)\n",
    "all_data = sec_helper.get_all_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "407bc769-45aa-44b4-96c8-24d14ca19040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# USE WHILE DEVELOPING to\n",
    "importlib.reload(company_data)\n",
    "sec_helper = company_data.SecurityData('tmp/fs',filename, all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e386e4c6-a489-46f2-b023-f58fb4313728",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "232"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sec_helper.total_securities_in_backtest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d04287fc-33e1-4934-8647-80000236de97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make this multi-GPU\n",
    "def run_model(prompt, tokenizer, model):\n",
    "    tokens = tokenizer.apply_chat_template(prompt, tokenize=False, add_generation_prompt=True)\n",
    "    model_inputs = tokenizer([tokens], return_tensors='pt').to('cuda')\n",
    "    generated_ids = model.generate(**model_inputs, pad_token_id=tokenizer.eos_token_id, max_new_tokens=5000)\n",
    "    parsed_ids = [\n",
    "        output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "    ]\n",
    "    return tokenizer.batch_decode(parsed_ids, skip_special_tokens=True)[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4396aaf6-8bc5-40e3-8b66-d740b9499d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_json(llm_output):\n",
    "    form = llm_output.replace('\\n','')\n",
    "    # Find the start and end of the JSON input\n",
    "    soj = form.find('```json')\n",
    "    eoj = form.find('}```')\n",
    "    # Pull out the additional context\n",
    "    additional = form[:soj]\n",
    "    additional += form[eoj + 4:]\n",
    "    json_obj = json.loads(form[soj + 7:eoj + 1])\n",
    "    json_obj['AdditionalContext'] = additional\n",
    "    return json_obj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457537ec-fb2b-4bba-8181-0eae4bdb92b4",
   "metadata": {},
   "source": [
    "## Run the backtest and generate all responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eea06af1-1e6f-43e6-9874-6e27ce8e1d1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'company_data' from '/project/company_data.py'>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(s3Helpers)\n",
    "importlib.reload(company_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "beeb6302-6ecf-483a-a191-67a49296cfdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = s3Helpers.Logger('tmp/fs')\n",
    "def run_backtest(company_info, tokenizer, model, logger, log_at=50, start_count=0):\n",
    "    # start the timer\n",
    "    start_time = datetime.datetime.now()\n",
    "    # get the dates\n",
    "    dates = company_info.get_dates()\n",
    "    # set the current date year\n",
    "    current_year = dates[0][:4]\n",
    "\n",
    "    # set the array\n",
    "    year_log = []\n",
    "    \n",
    "    # set up the display\n",
    "    max_count = company_info.total_securities_in_backtest()\n",
    "    f = IntProgress(min=0, max=max_count) # instantiate the bar\n",
    "    l = Label(value=str(f.value))\n",
    "    display(HBox([f,l]))\n",
    "    \n",
    "    count = 0\n",
    "\n",
    "    # run the backtest \n",
    "    for date in dates:\n",
    "        \n",
    "        securities = company_info.get_securities_reporting_on_date(date)\n",
    "\n",
    "        for security in securities:\n",
    "            \n",
    "            # allow model to start running from a pre-set point\n",
    "            if count >= start_count:\n",
    "                \n",
    "                # Save to S3 every 50 interations to ensure there is a cache\n",
    "                if count % log_at == 0:\n",
    "                    # save the file to S3 and reset when it is a new year\n",
    "                    logger.log(year_log, current_year + str(count) + '.json')\n",
    "                    # reset the stats\n",
    "                    year_log = []\n",
    "                    current_year = date[:4]\n",
    "\n",
    "\n",
    "                prompt = company_info.get_prompt(date, security, system_prompt)\n",
    "                response = run_model(prompt, tokenizer, model)\n",
    "                try:\n",
    "                    formatted_response = format_json(response)\n",
    "                    formatted_response['security'] = security\n",
    "                    formatted_response['date'] = date\n",
    "                    year_log.append(formatted_response)\n",
    "                except:\n",
    "                    print(\"error with \" + security + date)\n",
    "                    error_json = {'security': security, 'date': date, 'response': response}\n",
    "                    year_log.append(error_json)\n",
    "                    \n",
    "            # Interate along the backtest\n",
    "            f.value += 1\n",
    "            count += 1\n",
    "            l.value = str(count) + \"/\" + str(max_count)\n",
    "    \n",
    "    # Log the last values\n",
    "    logger.log(year_log, current_year + str(count) + '.json')\n",
    "    # end the timer\n",
    "    end_time = datetime.datetime.now()\n",
    "    print(\"Completed! Time to execute: \", end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8c692788-ce72-43ca-8009-ac7249d0e917",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fcc597cd03949a1b1e6d601c6e2d8f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=896), Label(value='0')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://awmgd-prod-finml-sandbox-user/bclarke16/tmp/fs/logs/2020800.json\n",
      "Saved s3://awmgd-prod-finml-sandbox-user/bclarke16/tmp/fs/logs/2020800.json\n",
      "error with XOM UN Equity2024-08-02\n",
      "error with CVX UN Equity2024-08-02\n",
      "error with AMGN UW Equity2024-08-06\n",
      "error with NVDA UQ Equity2024-08-28\n",
      "error with AXP UN Equity2024-10-18\n",
      "error with SHW UN Equity2024-10-22\n",
      "error with IBM UN Equity2024-10-23\n",
      "error with KO UN Equity2024-10-23\n",
      "error with DOW UN Equity2024-10-25\n",
      "error with AMGN UQ Equity2024-10-30\n",
      "error with CAT UN Equity2024-10-30\n",
      "error with MSFT UW Equity2024-10-30\n",
      "s3://awmgd-prod-finml-sandbox-user/bclarke16/tmp/fs/logs/2024850.json\n",
      "Saved s3://awmgd-prod-finml-sandbox-user/bclarke16/tmp/fs/logs/2024850.json\n",
      "error with INTC UW Equity2024-10-31\n",
      "error with CSCO UW Equity2024-11-13\n",
      "error with CSCO UQ Equity2024-11-13\n",
      "error with HD UN Equity2024-11-19\n",
      "error with NVDA UQ Equity2024-11-20\n",
      "error with JPM UN Equity2025-01-15\n",
      "error with MSFT UW Equity2025-01-29\n",
      "error with AAPL UQ Equity2025-01-30\n",
      "error with INTC UQ Equity2025-01-30\n",
      "error with AAPL UW Equity2025-01-31\n",
      "error with MRK UN Equity2025-02-04\n",
      "error with AMGN UW Equity2025-02-04\n",
      "s3://awmgd-prod-finml-sandbox-user/bclarke16/tmp/fs/logs/2024896.json\n",
      "Saved s3://awmgd-prod-finml-sandbox-user/bclarke16/tmp/fs/logs/2024896.json\n",
      "Completed! Time to execute:  2:40:45.779705\n"
     ]
    }
   ],
   "source": [
    "run_backtest(sec_helper, tokenizer, model, logger, 50, 800)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d54639-2bf0-4ee5-b28c-51067a50360e",
   "metadata": {},
   "source": [
    "### Concatenate all of the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "64b057d5-eb29-447e-ae65-cb23046ae4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = s3Helpers.Logger('tmp/fs')\n",
    "log_list = logger.get_list_of_logs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0045bda3-133e-4654-bfda-ebae2f39e4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "logs = logger.create_master_log(save_to_s3=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "bbc0f159-f6d1-4063-bc62-f4ce98759148",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_all_logs():\n",
    "    log_list = logger.get_list_of_logs()\n",
    "    logs = []\n",
    "    for logfile in log_list:\n",
    "        logs += logger.get_log(logfile[logfile.find('/logs/') + 6:])\n",
    "    return logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "3ed3b7a7-8293-4b44-b58f-f7fd8ca30a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "logs = concat_all_logs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "37b4fdad-d6a0-45c5-98fa-d5cd85bf745d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "909"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6a0bdb21-17b9-4b00-b6fd-2db26070b33e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "800"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(logs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d300bff-276f-445b-b98e-a3810e8d591f",
   "metadata": {},
   "source": [
    "## Multi GPU run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a03512-c413-4531-83c2-e254da5c54a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31bc5a8-5917-487d-a7d2-74253b928027",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "da415c52-15fc-4bd8-8917-805093786f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_json = [{'test':'test'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "968fe09b-51a7-4140-be96-b5e122aa594d",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.log(test_json, 'test.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "632f5d0d-e6c6-4260-84ba-2e0c965aa4b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bclarke16/tmp/fs/logs/20200.json',\n",
       " 'bclarke16/tmp/fs/logs/2020100.json',\n",
       " 'bclarke16/tmp/fs/logs/2020150.json',\n",
       " 'bclarke16/tmp/fs/logs/2020200.json',\n",
       " 'bclarke16/tmp/fs/logs/202050.json',\n",
       " 'bclarke16/tmp/fs/logs/2020800.json',\n",
       " 'bclarke16/tmp/fs/logs/2021250.json',\n",
       " 'bclarke16/tmp/fs/logs/2021300.json',\n",
       " 'bclarke16/tmp/fs/logs/2021350.json',\n",
       " 'bclarke16/tmp/fs/logs/2022400.json',\n",
       " 'bclarke16/tmp/fs/logs/2022450.json',\n",
       " 'bclarke16/tmp/fs/logs/2022500.json',\n",
       " 'bclarke16/tmp/fs/logs/2022550.json',\n",
       " 'bclarke16/tmp/fs/logs/2023600.json',\n",
       " 'bclarke16/tmp/fs/logs/2023650.json',\n",
       " 'bclarke16/tmp/fs/logs/2023700.json',\n",
       " 'bclarke16/tmp/fs/logs/2024750.json',\n",
       " 'bclarke16/tmp/fs/logs/2024800.json',\n",
       " 'bclarke16/tmp/fs/logs/2024850.json',\n",
       " 'bclarke16/tmp/fs/logs/2024896.json']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logger.get_list_of_logs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "94789e89-fe94-4060-aca1-5a0b23550c00",
   "metadata": {},
   "outputs": [],
   "source": [
    " d = logger.get_log('202010.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "3bf67b18-e45d-4b2d-80b7-c74901a168d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6508b723-ead0-49f3-b82b-e08f0303188a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sec_helper.get_security_statement('2020-01-31','AON UN Equity','is')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2e7b8120-2def-4fbd-84b8-6cd583928cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Data/base_deepseek_r2.json', 'w') as file:\n",
    "    json.dump(logs, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1104a472-6c11-4ddd-970d-d64fda33ca79",
   "metadata": {},
   "source": [
    "## Save any model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6def2848-5dd7-410e-9977-1cf3dfb422dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_helper = S3ModelHelper('tmp/fs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "634ec4d3-ca3f-40e7-8390-420b59c1bdc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bclarke16/tmp/fs/deepseek32/config.json\n",
      "bclarke16/tmp/fs/deepseek32/generation_config.json\n",
      "bclarke16/tmp/fs/deepseek32/model-00001-of-00004.safetensors\n",
      "bclarke16/tmp/fs/deepseek32/model-00002-of-00004.safetensors\n",
      "bclarke16/tmp/fs/deepseek32/model-00003-of-00004.safetensors\n",
      "bclarke16/tmp/fs/deepseek32/model-00004-of-00004.safetensors\n",
      "bclarke16/tmp/fs/deepseek32/model.safetensors.index.json\n",
      "Files deleted in S3\n"
     ]
    }
   ],
   "source": [
    "model_helper.delete_model_in_s3('deepseek32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd98c82f-eec9-4b94-b5b0-660117a746b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained('Data/DeepSeek32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8642f594-7220-42b0-9aae-4cc5a0cc4796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "model_helper.save_model_to_s3('Data/DeepSeek32','deepseek32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "64771e33-e965-4b7f-a378-608a2dcf5653",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_helper.clear_folder('Data/DeepSeek32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ee8fba-2085-45d2-8fd9-9dc4d39299c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_time = datetime.datetime.now()\n",
    "# #formatted_chat = tokenizer.apply_chat_template(prompt, tokenize=False, add_generation_prompt=True)\n",
    "# outputs = pipeline(\n",
    "#     prompt,\n",
    "#     max_new_tokens=1000,\n",
    "# )\n",
    "# end_time = datetime.datetime.now()\n",
    "# print(\"Time to execute: \", end_time - start_time)\n",
    "\n",
    "# test_output = outputs[0]['generated_text'][-1]\n",
    "# display(Markdown(test_output['content']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BQuant Python 3",
   "language": "python",
   "name": "remote-jupyterpython"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
