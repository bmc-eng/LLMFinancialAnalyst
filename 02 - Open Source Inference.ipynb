{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ea0b4d2-9a58-426f-a551-07d8d5eceae1",
   "metadata": {},
   "source": [
    "# Run Open Source Inference \n",
    "\n",
    "This notebook runs inference on the open source models using the multi-gpu process implemented in the modelinference file. This file requires the llm-base environment to run correctly. The results of the backtest are stored in the Data folder under each model folder. \n",
    "\n",
    "We test with a handful of open source models:\n",
    "\n",
    "- Llama 3.2 3B Instruct\n",
    "- Qwen 2.5 7B Instruct\n",
    "- Deepseek\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d33e342b-edf8-4ce9-8a44-759d241f1fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import model_inference\n",
    "import prompts\n",
    "import importlib\n",
    "import datetime\n",
    "import torch\n",
    "from huggingface_hub import login\n",
    "import utils.model_helper as mh\n",
    "\n",
    "from transformers import BitsAndBytesConfig\n",
    "from accelerate import Accelerator, notebook_launcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1dcf2505-c7f9-440e-91f1-323f2922817a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils.model_helper' from '/project/utils/model_helper.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(model_inference)\n",
    "importlib.reload(prompts)\n",
    "importlib.reload(mh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d3e71f-48ee-483a-b834-17fea3d28a04",
   "metadata": {},
   "source": [
    "### Set up the environment\n",
    "Log into Huggingface and check the number of GPUs available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a89aad1-f53b-4d47-840c-5d6c0556f0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log into Huggingface\n",
    "with open('pass.txt') as p:\n",
    "    hf_login = p.read()\n",
    "    \n",
    "hf_login = hf_login[hf_login.find('=')+1:hf_login.find('\\n')]\n",
    "login(hf_login, add_to_git_credential=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dff8b64b-1dfa-4073-96ba-41f89ceab9dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 2.1.2.post300\n",
      "Device Count: 2\n"
     ]
    }
   ],
   "source": [
    "print(f'Torch version: {torch.__version__}')\n",
    "print(f'Device Count: {torch.cuda.device_count()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca868c0b-6b7d-4c03-b4a3-6a01b55c6c5c",
   "metadata": {},
   "source": [
    "### Run 1: Llama 3.2 Earning analysis - Base\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f2ac3bb-0cb4-49a0-9342-af022c765db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the run config\n",
    "run_config = {\n",
    "    'model_hf_id': 'meta-llama/Llama-3.2-3B-Instruct',\n",
    "    'model_s3_loc': 'llama',\n",
    "    'model_reload': False,\n",
    "    'model_quant': None,\n",
    "    'system_prompt': prompts.SYSTEM_PROMPTS['BASE_EARN'],\n",
    "    'multi-gpu':True,\n",
    "    'dataset': 'data_quarterly_pit_indu_blended',\n",
    "    'data_location': 'data_quarterly_pit_indu_refresh_blended.json'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a56b0b4b-b11d-4b0a-9fb5-6c2da4124f90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requesting all datasets...\n",
      "Saving data...\n"
     ]
    }
   ],
   "source": [
    "run_name = f\"{run_config['model_s3_loc']}_{run_config['dataset']}\"\n",
    "ir = model_inference.InferenceRun(run_name, run_config)\n",
    "\n",
    "# Create the prompts and save to the Data folder\n",
    "prompt_set = ir.create_all_prompts(force_refresh=True, is_save_prompts=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cff85cc3-7825-4367-b9c5-5858170939f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching training on 4 GPUs.\n",
      "llamallama\n",
      "\n",
      "llama\n",
      "llama\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d0c0f6537e14fb18a46d133b63e9b0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5929afc071654183b69333d27c30d4a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e48f5735688436fb11462e7a6a231bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea30f12d92a94642a3e6889794f3bc74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting...\n",
      "Waiting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/887 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory footprint: 6.4 GB\n",
      "Waiting...\n",
      "starting backtest...\n",
      "starting backtest...\n",
      "starting backtest...\n",
      "starting backtest...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "888it [26:41,  2.21s/it]                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished run...\n",
      "Finished run...\n",
      "Finished run...\n",
      "Finished run...\n",
      "Gathered results...Gathered results...Gathered results...Gathered results...\n",
      "\n",
      "\n",
      "\n",
      "Finished run in 0:28:23.145980\n",
      "Called Save run\n",
      "called log\n",
      "Saved bclarke16/tmp/fs/logs/Results_2025-03-30 10:05:34.896587.json\n",
      "Run Completed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "888it [28:23,  1.92s/it]\n",
      "[2025-03-30 10:34:55,568] torch.distributed.elastic.multiprocessing.api: [WARNING] Closing process 2401 via signal SIGTERM\n",
      "[2025-03-30 10:34:55,569] torch.distributed.elastic.multiprocessing.api: [WARNING] Closing process 2402 via signal SIGTERM\n",
      "[2025-03-30 10:34:55,570] torch.distributed.elastic.multiprocessing.api: [WARNING] Closing process 2403 via signal SIGTERM\n"
     ]
    }
   ],
   "source": [
    "# Run the multi-gpu model with notebook_launcher\n",
    "notebook_launcher(ir.run_multi_gpu, num_processes=torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0779e2-8a65-4167-99d7-19af14ae0051",
   "metadata": {},
   "source": [
    "### Run 2: Llama 3.2 Earning analysis - Chain of Thought\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e6b92c1-b6a6-4b8b-a6f1-873c8a146dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_config = {\n",
    "    'model_hf_id': 'meta-llama/Llama-3.2-3B-Instruct',\n",
    "    'model_s3_loc': 'llama',\n",
    "    'model_reload': False,\n",
    "    'model_quant': None,\n",
    "    'system_prompt': prompts.SYSTEM_PROMPTS['COT_EARN'],\n",
    "    'multi-gpu':True,\n",
    "    'dataset': 'data_quarterly_pit_indu_blended_cot',\n",
    "    'data_location': 'data_quarterly_pit_indu_refresh_blended.json'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0970f294-cdf5-4885-b71c-9cf888d13cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requesting all datasets...\n",
      "Saving data...\n"
     ]
    }
   ],
   "source": [
    "run_name = f\"{run_config['model_s3_loc']}_{run_config['dataset']}\"\n",
    "ir = model_inference.InferenceRun(run_name, run_config)\n",
    "\n",
    "# Create the prompts and save to the Data folder\n",
    "prompt_set = ir.create_all_prompts(force_refresh=True, is_save_prompts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5bf2d3c2-6e5f-46ca-94b9-bbd515903613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching training on 4 GPUs.\n",
      "llama\n",
      "llama\n",
      "llama\n",
      "llama\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62a1ce1191154bb1acfc79a38fadfdf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00055e73a7b14b69b56b806e8d3e1fbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce2f668434e44e4eacc44138378617da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f8941089c7e421cad94322f3198a594",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting...\n",
      "Waiting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/887 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory footprint: 6.4 GB\n",
      "Waiting...\n",
      "starting backtest...\n",
      "starting backtest...\n",
      "starting backtest...\n",
      "starting backtest...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 812/887 [53:59<04:41,  3.75s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished run...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 840/887 [56:09<03:06,  3.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished run...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 868/887 [58:12<01:21,  4.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished run...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "888it [59:41,  4.45s/it]                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished run...\n",
      "Gathered results...Gathered results...Gathered results...Gathered results...\n",
      "\n",
      "\n",
      "\n",
      "Finished run in 0:59:41.735791\n",
      "Called Save run\n",
      "called log\n",
      "Saved bclarke16/tmp/fs/logs/Results_2025-03-30 10:36:38.332729.json\n",
      "Run Completed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "888it [59:42,  4.03s/it]\n",
      "[2025-03-30 11:37:17,363] torch.distributed.elastic.multiprocessing.api: [WARNING] Closing process 3624 via signal SIGTERM\n",
      "[2025-03-30 11:37:17,365] torch.distributed.elastic.multiprocessing.api: [WARNING] Closing process 3626 via signal SIGTERM\n",
      "[2025-03-30 11:37:17,365] torch.distributed.elastic.multiprocessing.api: [WARNING] Closing process 3627 via signal SIGTERM\n"
     ]
    }
   ],
   "source": [
    "# Run the multi-gpu model with notebook_launcher\n",
    "notebook_launcher(ir.run_multi_gpu, num_processes=torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213e5438-aa23-430f-93d8-8f632e1a950d",
   "metadata": {},
   "source": [
    "### Run 3: DeepSeek R1 Qwen 7B Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3485696-9d28-4ce8-b41c-a2b6e09a0a49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b426d33722824b6394cd1dddd37c8e2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "quant_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    bnb_4bit_quant_type=\"nf4\"\n",
    "\n",
    ")\n",
    "\n",
    "model_helper = mh.ModelHelper('tmp/fs')\n",
    "model_helper.get_model_and_save('deepseek-ai/DeepSeek-R1-Distill-Qwen-7B',\n",
    "                                'deepseek7B', \n",
    "                                'Data',\n",
    "                                True,\n",
    "                                quant_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02500a92-6c4d-47ec-a87f-d36c9e1633f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_config = {\n",
    "    'model_hf_id': 'deepseek-ai/DeepSeek-R1-Distill-Qwen-7B',\n",
    "    'model_s3_loc': 'deepseek7B',\n",
    "    'model_reload': False,\n",
    "    'model_quant': None,\n",
    "    'system_prompt': prompts.SYSTEM_PROMPTS['BASE_EARN'],\n",
    "    'multi-gpu':True,\n",
    "    'dataset': 'data_quarterly_pit_indu_blended_base',\n",
    "    'data_location': 'data_quarterly_pit_indu_refresh_blended.json'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18257919-498e-4d66-80a2-50cf3f6a51d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requesting all datasets...\n",
      "Saving data...\n"
     ]
    }
   ],
   "source": [
    "run_name = f\"{run_config['model_s3_loc']}_{run_config['dataset']}\"\n",
    "ir = model_inference.InferenceRun(run_name, run_config)\n",
    "\n",
    "# Create the prompts and save to the Data folder\n",
    "prompt_set = ir.create_all_prompts(force_refresh=True, is_save_prompts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "975b7ad7-6985-46e0-9bc9-656fff07665d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching training on 8 GPUs.\n",
      "deepseek7B\n",
      "deepseek7B\n",
      "deepseek7B\n",
      "deepseek7B\n",
      "deepseek7B\n",
      "deepseek7B\n",
      "deepseek7Bdeepseek7B\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n",
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b022893e2fc94874a032fb4fad9b1cc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e9d96d0a756423aa034b4e0ea289a45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n",
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n",
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n",
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n",
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n",
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d70d4f29c86f426b98cf6ae6dc88eba9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ddc747a4bb142a5aa9e84e20cc68aca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21627aaa81a34e4fa858deea9084ee30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18e7e38fe7e04341a8bf637fabafab68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4aa290fb5544721a95b943f679664ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "533094192bfc41aaae4b24bcc89b5d5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c7f1eeb40474823835669b8af7ee8b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/3.07k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b6de0bd4687443298abd480fe06777f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/7.03M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/887 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory footprint: 5.4 GB\n",
      "starting backtest...starting backtest...starting backtest...\n",
      "\n",
      "\n",
      "starting backtest...starting backtest...\n",
      "starting backtest...\n",
      "\n",
      "starting backtest...\n",
      "starting backtest...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "888it [2:17:03,  9.49s/it]                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished run in 2:17:37.334527\n",
      "Called Save run\n",
      "called log\n",
      "Saved bclarke16/tmp/fs/logs/Results_2025-03-30 17:44:18.481428.json\n",
      "Run Completed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "888it [2:17:37,  9.30s/it]\n",
      "[2025-03-30 20:02:58,292] torch.distributed.elastic.multiprocessing.api: [WARNING] Closing process 187 via signal SIGTERM\n",
      "[2025-03-30 20:02:58,294] torch.distributed.elastic.multiprocessing.api: [WARNING] Closing process 188 via signal SIGTERM\n",
      "[2025-03-30 20:02:58,294] torch.distributed.elastic.multiprocessing.api: [WARNING] Closing process 189 via signal SIGTERM\n",
      "[2025-03-30 20:02:58,295] torch.distributed.elastic.multiprocessing.api: [WARNING] Closing process 190 via signal SIGTERM\n",
      "[2025-03-30 20:02:58,296] torch.distributed.elastic.multiprocessing.api: [WARNING] Closing process 192 via signal SIGTERM\n",
      "[2025-03-30 20:02:58,297] torch.distributed.elastic.multiprocessing.api: [WARNING] Closing process 193 via signal SIGTERM\n",
      "[2025-03-30 20:02:58,297] torch.distributed.elastic.multiprocessing.api: [WARNING] Closing process 194 via signal SIGTERM\n"
     ]
    }
   ],
   "source": [
    "# Run the multi-gpu model with notebook_launcher\n",
    "notebook_launcher(ir.run_multi_gpu, num_processes=torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b984dbc-7874-46ae-9b84-3e9100f54735",
   "metadata": {},
   "source": [
    "### Run 4: DeepSeek 7B COT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02aea17c-33e8-4ed7-9fd7-ebcf73b6ecb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_config = {\n",
    "    'model_hf_id': 'deepseek-ai/DeepSeek-R1-Distill-Qwen-7B',\n",
    "    'model_s3_loc': 'deepseek7B',\n",
    "    'model_reload': False,\n",
    "    'model_quant': None,\n",
    "    'system_prompt': prompts.SYSTEM_PROMPTS['COT_EARN'],\n",
    "    'multi-gpu':True,\n",
    "    'dataset': 'data_quarterly_pit_indu_blended_base',\n",
    "    'data_location': 'data_quarterly_pit_indu_refresh_blended.json'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ddd0d50b-6c95-4ce5-b503-12215cfe902d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requesting all datasets...\n",
      "Saving data...\n"
     ]
    }
   ],
   "source": [
    "run_name = f\"{run_config['model_s3_loc']}_{run_config['dataset']}\"\n",
    "ir = model_inference.InferenceRun(run_name, run_config)\n",
    "\n",
    "# Create the prompts and save to the Data folder\n",
    "prompt_set = ir.create_all_prompts(force_refresh=True, is_save_prompts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae221de2-c71d-49f9-ab74-23876c132ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching training on 8 GPUs.\n",
      "deepseek7B\n",
      "deepseek7B\n",
      "deepseek7B\n",
      "deepseek7B\n",
      "deepseek7B\n",
      "deepseek7B\n",
      "deepseek7B\n",
      "deepseek7B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n",
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n",
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n",
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n",
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n",
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n",
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n",
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11faff2b6a724e0fa15daf54d72a89e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10c953bf644c4a9ea4b69bdfcbc5c560",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "529da691ffcf4c7195160cf33f24b42e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e727ab9919754053a8151c3d45a743c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3908dcf8b744a2bac73be9afbb4c079",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76ab89be3fac4a4e81e1ef1df0271f24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9536a6a9c79b4633abc4a15455bdfe55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ae19905fff644e583df3ddbd20757d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/887 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory footprint: 5.4 GB\n",
      "starting backtest...starting backtest...starting backtest...\n",
      "starting backtest...\n",
      "\n",
      "starting backtest...\n",
      "\n",
      "starting backtest...\n",
      "starting backtest...\n",
      "starting backtest...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "888it [2:26:10,  9.47s/it]                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished run in 2:30:12.540523\n",
      "Called Save run\n",
      "called log\n",
      "Saved bclarke16/tmp/fs/logs/Results_2025-03-30 20:11:39.828629.json\n",
      "Run Completed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "888it [2:30:13, 10.15s/it]\n",
      "[2025-03-30 22:42:55,767] torch.distributed.elastic.multiprocessing.api: [WARNING] Closing process 3671 via signal SIGTERM\n",
      "[2025-03-30 22:42:55,768] torch.distributed.elastic.multiprocessing.api: [WARNING] Closing process 3672 via signal SIGTERM\n",
      "[2025-03-30 22:42:55,769] torch.distributed.elastic.multiprocessing.api: [WARNING] Closing process 3673 via signal SIGTERM\n",
      "[2025-03-30 22:42:55,770] torch.distributed.elastic.multiprocessing.api: [WARNING] Closing process 3674 via signal SIGTERM\n",
      "[2025-03-30 22:42:55,771] torch.distributed.elastic.multiprocessing.api: [WARNING] Closing process 3676 via signal SIGTERM\n",
      "[2025-03-30 22:42:55,771] torch.distributed.elastic.multiprocessing.api: [WARNING] Closing process 3677 via signal SIGTERM\n",
      "[2025-03-30 22:42:55,772] torch.distributed.elastic.multiprocessing.api: [WARNING] Closing process 3678 via signal SIGTERM\n"
     ]
    }
   ],
   "source": [
    "notebook_launcher(ir.run_multi_gpu, num_processes=torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00f8ebc-2756-4eb0-a2d9-777fc5fd0bb9",
   "metadata": {},
   "source": [
    "### Qwen 2.5 - 3B Instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c8e7142-b8f5-4bc6-8a93-fb9c20247fcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db4484d647b84a67bf1e5b5b64aac13b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/661 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f35b7dae13724b98a5ee535ee28c6be5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/35.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0507125d34b4cd6a289d8bea03da158",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e94d0ca6ae014523b3ae08440e6e1081",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/3.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca50a003196b45beb23eac1e8cf70741",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/2.20G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1a49654268841bd9e6854a674361ba5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "531e8f2f215543cc8097ebbe180d661c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/242 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "quant_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    bnb_4bit_quant_type=\"nf4\"\n",
    "\n",
    ")\n",
    "\n",
    "model_helper = mh.ModelHelper('tmp/fs')\n",
    "model_helper.get_model_and_save('Qwen/Qwen2.5-3B-Instruct',\n",
    "                                'qwen3b', \n",
    "                                'Data',\n",
    "                                True,\n",
    "                                quant_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0be801bc-c018-42b4-98a0-ebacbc024890",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_config = {\n",
    "    'model_hf_id': 'Qwen/Qwen2.5-3B-Instruct',\n",
    "    'model_s3_loc': 'qwen3b',\n",
    "    'model_reload': False,\n",
    "    'model_quant': None,\n",
    "    'system_prompt': prompts.SYSTEM_PROMPTS['BASE_EARN'],\n",
    "    'multi-gpu':True,\n",
    "    'dataset': 'data_quarterly_pit_indu_blended_base',\n",
    "    'data_location': 'data_quarterly_pit_indu_refresh_blended.json'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb76425a-1690-4998-8448-a4d439685fa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requesting all datasets...\n",
      "Saving data...\n"
     ]
    }
   ],
   "source": [
    "run_name = f\"{run_config['model_s3_loc']}_{run_config['dataset']}\"\n",
    "ir = model_inference.InferenceRun(run_name, run_config)\n",
    "\n",
    "# Create the prompts and save to the Data folder\n",
    "prompt_set = ir.create_all_prompts(force_refresh=True, is_save_prompts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c54db2c-0ede-4571-a364-90f688cf462f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3b1ac792-d286-4374-977e-a9ae6a0a352b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "run_config = {\n",
    "    'model_hf_id': 'deepseek-ai/DeepSeek-R1-Distill-Qwen-14B',\n",
    "    'model_s3_loc': 'deepseek14Q',\n",
    "    'model_reload': False,\n",
    "    'model_quant': None,\n",
    "    'system_prompt': prompts.SYSTEM_PROMPTS['CoT'],\n",
    "    'multi-gpu':True,\n",
    "    'dataset': 'data_annual_pit_spx',\n",
    "    'data_location': 'data_annual_pit_spx.json'\n",
    "}\n",
    "\n",
    "run_config = {\n",
    "    'model_hf_id': 'Qwen/Qwen2.5-7B-Instruct',\n",
    "    'model_s3_loc': 'qwen',\n",
    "    'model_reload': False,\n",
    "    'model_quant': None,\n",
    "    'system_prompt': prompts.SYSTEM_PROMPTS['BASE'],\n",
    "    'multi-gpu':True,\n",
    "    'dataset': 'data_quarterly_pit_indu',\n",
    "    'data_location': 'data_quarterly_pit_indu.json'\n",
    "}\n",
    "\n",
    "# RUN 1\n",
    "run_config = {\n",
    "    'model_hf_id': 'meta-llama/Llama-3.2-3B-Instruct',\n",
    "    'model_s3_loc': 'llama',\n",
    "    'model_reload': False,\n",
    "    'model_quant': None,\n",
    "    'system_prompt': prompts.SYSTEM_PROMPTS['BASE'],\n",
    "    'multi-gpu':True,\n",
    "    'dataset': 'data_quarterly_pit_indu',\n",
    "    'data_location': 'data_quarterly_pit_indu.json'\n",
    "}\n",
    "\n",
    "# RUN 2\n",
    "run_config = {\n",
    "    'model_hf_id': 'meta-llama/Llama-3.2-3B-Instruct',\n",
    "    'model_s3_loc': 'llama',\n",
    "    'model_reload': False,\n",
    "    'model_quant': None,\n",
    "    'system_prompt': prompts.SYSTEM_PROMPTS['CoT'],\n",
    "    'multi-gpu':True,\n",
    "    'dataset': 'data_quarterly_pit_indu',\n",
    "    'data_location': 'data_quarterly_pit_indu.json'\n",
    "}\n",
    "\n",
    "# RUN 3\n",
    "run_config = {\n",
    "    'model_hf_id': 'deepseek-ai/DeepSeek-R1-Distill-Qwen-14B',\n",
    "    'model_s3_loc': 'deepseek14Q',\n",
    "    'model_reload': False,\n",
    "    'model_quant': None,\n",
    "    'system_prompt': prompts.SYSTEM_PROMPTS['BASE'],\n",
    "    'multi-gpu':True,\n",
    "    'dataset': 'data_quarterly_pit_indu',\n",
    "    'data_location': 'data_quarterly_pit_indu.json'\n",
    "}\n",
    "\n",
    "# RUN 4\n",
    "run_config = {\n",
    "    'model_hf_id': 'deepseek-ai/DeepSeek-R1-Distill-Qwen-14B',\n",
    "    'model_s3_loc': 'deepseek14Q',\n",
    "    'model_reload': False,\n",
    "    'model_quant': None,\n",
    "    'system_prompt': prompts.SYSTEM_PROMPTS['CoT'],\n",
    "    'multi-gpu':True,\n",
    "    'dataset': 'data_quarterly_pit_indu',\n",
    "    'data_location': 'data_quarterly_pit_indu.json'\n",
    "}\n",
    "\n",
    "# RUN 5 - failed\n",
    "run_config = {\n",
    "    'model_hf_id': 'deepseek-ai/DeepSeek-R1-Distill-Qwen-32B',\n",
    "    'model_s3_loc': 'deepseek32',\n",
    "    'model_reload': False,\n",
    "    'model_quant': None,\n",
    "    'system_prompt': prompts.SYSTEM_PROMPTS['CoT'],\n",
    "    'multi-gpu':True,\n",
    "    'dataset': 'data_quarterly_pit_indu',\n",
    "    'data_location': 'data_quarterly_pit_indu.json'\n",
    "}\n",
    "\n",
    "# Run 6 - failed\n",
    "run_config = {\n",
    "    'model_hf_id': 'Qwen/Qwen2.5-7B-Instruct',\n",
    "    'model_s3_loc': 'qwen',\n",
    "    'model_reload': False,\n",
    "    'model_quant': None,\n",
    "    'system_prompt': prompts.SYSTEM_PROMPTS['CoTDetailed'],\n",
    "    'multi-gpu':True,\n",
    "    'dataset': 'data_quarterly_pit_indu',\n",
    "    'data_location': 'data_quarterly_pit_indu.json'\n",
    "}\n",
    "\n",
    "run_config = {\n",
    "    'model_hf_id': 'meta-llama/Llama-3.2-3B-Instruct',\n",
    "    'model_s3_loc': 'llama',\n",
    "    'model_reload': False,\n",
    "    'model_quant': None,\n",
    "    'system_prompt': prompts.SYSTEM_PROMPTS['BASE_EARN'],\n",
    "    'multi-gpu':True,\n",
    "    'dataset': 'data_quarterly_pit_indu_refresh_v2',\n",
    "    'data_location': 'data_quarterly_pit_indu_refresh_v2.json'\n",
    "}\n",
    "\n",
    "# run_config = {\n",
    "#     'model_hf_id': 'meta-llama/Llama-3.2-3B-Instruct',\n",
    "#     'model_s3_loc': 'llama',\n",
    "#     'model_reload': False,\n",
    "#     'model_quant': None,\n",
    "#     'system_prompt': prompts.SYSTEM_PROMPTS['COT_EARN'],\n",
    "#     'multi-gpu':True,\n",
    "#     'dataset': 'data_quarterly_pit_indu',\n",
    "#     'data_location': 'data_quarterly_pit_indu.json'\n",
    "# }\n",
    "\n",
    "\n",
    "\n",
    "run_name = f\"{run_config['model_s3_loc']}_{run_config['dataset']}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fe94d167-f17d-4a2e-be69-db2210d4bd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ir = model_inference.InferenceRun(run_name, run_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "abf93574-9fd9-4739-89eb-77941804fe03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requesting all datasets...\n",
      "Saving data...\n"
     ]
    }
   ],
   "source": [
    "# Create the prompts and save to the Data folder\n",
    "prompts = ir.create_all_prompts(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0a0f3e83-e637-4d70-88a8-39b5a2d6e734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching training on 4 GPUs.\n",
      "llama\n",
      "llama\n",
      "llama\n",
      "llama\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb37171aae694fd195996b4ccda5320f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86688187a52642aa9e11e53cff75c80c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1171c4eb5c2f43f8b324488a31c2ed1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b891ef7620a4f4d9769c56708e000f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a04af17ad7cf4a93a3bdd906f3e1280b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/54.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b911d278f32f4d7cba8d9dee72d80bf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdd4f87d1ee54fbe8342687ae40042e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/296 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/891 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory footprint: 6.4 GB\n",
      "Waiting...\n",
      "Waiting...\n",
      "Waiting...\n",
      "Waiting...\n",
      "starting backtest...\n",
      "starting backtest...\n",
      "starting backtest...\n",
      "starting backtest...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 884/891 [27:05<00:12,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished run...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 888/891 [27:10<00:04,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished run...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "892it [27:19,  1.82s/it]                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished run...\n",
      "Finished run...\n",
      "Gathered results...Gathered results...Gathered results...Gathered results...\n",
      "\n",
      "\n",
      "\n",
      "Finished run in 0:27:51.318931\n",
      "Called Save run\n",
      "called log\n",
      "Saved bclarke16/tmp/fs/logs/Results_2025-03-30 09:15:48.238865.json\n",
      "Run Completed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "892it [27:51,  1.87s/it]\n",
      "[2025-03-30 09:44:39,571] torch.distributed.elastic.multiprocessing.api: [WARNING] Closing process 257 via signal SIGTERM\n",
      "[2025-03-30 09:44:39,572] torch.distributed.elastic.multiprocessing.api: [WARNING] Closing process 258 via signal SIGTERM\n",
      "[2025-03-30 09:44:39,573] torch.distributed.elastic.multiprocessing.api: [WARNING] Closing process 260 via signal SIGTERM\n"
     ]
    }
   ],
   "source": [
    "# Run the multi-gpu model with notebook_launcher\n",
    "notebook_launcher(ir.run_multi_gpu, num_processes=torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03dc716-b772-49fc-8b42-4f0ecf2fbfe6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9642caf9-5b73-4fb8-b32f-19717c4ca374",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb455d3-7150-455d-99d8-8c72b787f33b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef28887-fe90-4d2d-b069-8a425e5d9a97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f54ebba-0ee4-40a4-a92c-74a1f882d380",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf4d6235-af59-4924-b54b-72ad749bd686",
   "metadata": {},
   "outputs": [],
   "source": [
    "ir = model_inference.InferenceRun(run_name, run_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7925f016-9392-4142-a9ec-a6872af1bae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requesting all datasets...\n",
      "Saving data...\n"
     ]
    }
   ],
   "source": [
    "p1 = ir.create_all_prompts(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14fd8453-b388-488c-b553-aaff3333ea23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "896"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff153540-48a0-4059-acf8-bae25ca9dd78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deepseek32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a2a95716048465abd4618c818c8f93f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = ir.load_model_from_storage(ir.model_s3_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "370eddfa-1f87-4ac9-863f-57434aed7ca0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Qwen2Config {\n",
       "  \"_attn_implementation_autoset\": true,\n",
       "  \"_name_or_path\": \"deepseek32\",\n",
       "  \"architectures\": [\n",
       "    \"Qwen2ForCausalLM\"\n",
       "  ],\n",
       "  \"attention_dropout\": 0.0,\n",
       "  \"bos_token_id\": 151643,\n",
       "  \"eos_token_id\": 151643,\n",
       "  \"hidden_act\": \"silu\",\n",
       "  \"hidden_size\": 5120,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 27648,\n",
       "  \"max_position_embeddings\": 131072,\n",
       "  \"max_window_layers\": 64,\n",
       "  \"model_type\": \"qwen2\",\n",
       "  \"num_attention_heads\": 40,\n",
       "  \"num_hidden_layers\": 64,\n",
       "  \"num_key_value_heads\": 8,\n",
       "  \"quantization_config\": {\n",
       "    \"_load_in_4bit\": true,\n",
       "    \"_load_in_8bit\": false,\n",
       "    \"bnb_4bit_compute_dtype\": \"bfloat16\",\n",
       "    \"bnb_4bit_quant_storage\": \"uint8\",\n",
       "    \"bnb_4bit_quant_type\": \"nf4\",\n",
       "    \"bnb_4bit_use_double_quant\": true,\n",
       "    \"llm_int8_enable_fp32_cpu_offload\": false,\n",
       "    \"llm_int8_has_fp16_weight\": false,\n",
       "    \"llm_int8_skip_modules\": null,\n",
       "    \"llm_int8_threshold\": 6.0,\n",
       "    \"load_in_4bit\": true,\n",
       "    \"load_in_8bit\": false,\n",
       "    \"quant_method\": \"bitsandbytes\"\n",
       "  },\n",
       "  \"rms_norm_eps\": 1e-05,\n",
       "  \"rope_scaling\": null,\n",
       "  \"rope_theta\": 1000000.0,\n",
       "  \"sliding_window\": null,\n",
       "  \"tie_word_embeddings\": false,\n",
       "  \"torch_dtype\": \"bfloat16\",\n",
       "  \"transformers_version\": \"4.48.3\",\n",
       "  \"use_cache\": true,\n",
       "  \"use_sliding_window\": false,\n",
       "  \"vocab_size\": 152064\n",
       "}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dfcdf6bf-07d3-4fb0-87de-034e94e92a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cdf599ad-b6de-4a30-b48a-7c30a97ce88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(ir.model_hf_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7a9cff15-9c86-48fd-be61-10bd0d160f83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running model...\n"
     ]
    }
   ],
   "source": [
    "output_result = ir.run_model(p1[0]['prompt'],tokenizer,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f86f4a03-2196-434b-b5a1-22f2435f9066",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_result = {\"date\": \"2020-02-06\", \"security\": \"MMM UN Equity\", \"response\": \"Here is the JSON response:\\n\\n```json\\n{\\n  \\\"decision\\\": \\\"BUY\\\",\\n  \\\"confidence score\\\": 80,\\n  \\\"reason\\\": \\\"Gross profit and EPS have increased over time, indicating a strong financial performance\\\"\\n}\\n```\\n\\nI have computed the following financial ratios:\\n\\n1. Gross Margin: \\n   - 2020: 3.786000e+09 / 8.111000e+09 = 0.466\\n   - 2019: 3.803000e+09 / 7.991000e+09 = 0.477\\n   - 2018: 3.858000e+09 / 8.171000e+09 = 0.471\\n   - 2017: 3.553000e+09 / 7.863000e+09 = 0.453\\n   - 2016: 3.885000e+09 / 7.945000e+09 = 0.492\\n\\nThe gross margin has been increasing over time, indicating a strong financial performance.\\n\\n2. EPS:\\n   - 2020: 9.690000e+08 / 1.012600e+10 = 0.953\\n   - 2019: 1.583000e+09 / 1.076400e+10 = 1.465\\n   - 2018: 1.127000e+09 / 1.014200e+10 = 1.117\\n   - 2017: 1.347000e+09 / 9.848000e+09 = 0.137\\n   - 2016: 1.543000e+09 / 9.848000e+09 = 0.156\\n\\nThe EPS has been increasing over time, indicating a strong financial performance.\\n\\n3. Current Ratio:\\n   - 2020: 2.441000e+09 / 9.222000e+09 = 0.264\\n   - 2019: 1.588000e+09 / 7.821000e+09 = 0.201\\n   - 2018: 1.131000e+09 / 7.265000e+09 = 0.157\\n   - 2017: 8.930000e+08 / 7.244000e+09 = 0.123\\n   - 2016: 8.910000e+08 / 5.020000e+09 = 0.177\\n\\nThe current ratio has been increasing over time, indicating a strong financial performance.\\n\\nBased on these financial ratios, the company has been performing well financially and has a strong track record of increasing gross profit and EPS over time. Therefore, I recommend a BUY decision with a confidence score of 80.\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5457878-488c-48d5-935b-44cf0427b19c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Here is the JSON response:\\n\\n```json\\n{\\n  \"decision\": \"BUY\",\\n  \"confidence score\": 80,\\n  \"reason\": \"Gross profit and EPS have increased over time, indicating a strong financial performance\"\\n}\\n```\\n\\nI have computed the following financial ratios:\\n\\n1. Gross Margin: \\n   - 2020: 3.786000e+09 / 8.111000e+09 = 0.466\\n   - 2019: 3.803000e+09 / 7.991000e+09 = 0.477\\n   - 2018: 3.858000e+09 / 8.171000e+09 = 0.471\\n   - 2017: 3.553000e+09 / 7.863000e+09 = 0.453\\n   - 2016: 3.885000e+09 / 7.945000e+09 = 0.492\\n\\nThe gross margin has been increasing over time, indicating a strong financial performance.\\n\\n2. EPS:\\n   - 2020: 9.690000e+08 / 1.012600e+10 = 0.953\\n   - 2019: 1.583000e+09 / 1.076400e+10 = 1.465\\n   - 2018: 1.127000e+09 / 1.014200e+10 = 1.117\\n   - 2017: 1.347000e+09 / 9.848000e+09 = 0.137\\n   - 2016: 1.543000e+09 / 9.848000e+09 = 0.156\\n\\nThe EPS has been increasing over time, indicating a strong financial performance.\\n\\n3. Current Ratio:\\n   - 2020: 2.441000e+09 / 9.222000e+09 = 0.264\\n   - 2019: 1.588000e+09 / 7.821000e+09 = 0.201\\n   - 2018: 1.131000e+09 / 7.265000e+09 = 0.157\\n   - 2017: 8.930000e+08 / 7.244000e+09 = 0.123\\n   - 2016: 8.910000e+08 / 5.020000e+09 = 0.177\\n\\nThe current ratio has been increasing over time, indicating a strong financial performance.\\n\\nBased on these financial ratios, the company has been performing well financially and has a strong track record of increasing gross profit and EPS over time. Therefore, I recommend a BUY decision with a confidence score of 80.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_result['response']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5728ba70-2042-4250-af42-cac37f26eaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "30024d1f-b16b-4214-962c-190106dc2d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_json(llm_output):\n",
    "    # remove all the broken lines\n",
    "    form = llm_output.replace('\\n','')\n",
    "    # Find the start and end of the JSON input\n",
    "    #try:\n",
    "    soj = form.find('```json')\n",
    "    eoj = form.find('}```')\n",
    "\n",
    "    if eoj == -1:\n",
    "        eoj = len(llm_output)\n",
    "        llm_output = llm_output + '}```'\n",
    "    # Pull out the additional context\n",
    "    additional = form[:soj]\n",
    "    additional += form[eoj + 4:]\n",
    "    json_obj = json.loads(form[soj + 7:eoj + 1])\n",
    "    json_obj['AdditionalContext'] = additional\n",
    "    return json_obj\n",
    "    #except:\n",
    "    #    return llm_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "73b1782b-e52e-407d-b9d6-2d691cb8fc55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{  \"decision\": \"BUY\",  \"confidence score\": 80,  \"reason\": \"Gross profit and EPS have increased over time, indicating a strong financial performance\"}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'decision': 'BUY',\n",
       " 'confidence score': 80,\n",
       " 'reason': 'Gross profit and EPS have increased over time, indicating a strong financial performance',\n",
       " 'AdditionalContext': 'Here is the JSON response:I have computed the following financial ratios:1. Gross Margin:    - 2020: 3.786000e+09 / 8.111000e+09 = 0.466   - 2019: 3.803000e+09 / 7.991000e+09 = 0.477   - 2018: 3.858000e+09 / 8.171000e+09 = 0.471   - 2017: 3.553000e+09 / 7.863000e+09 = 0.453   - 2016: 3.885000e+09 / 7.945000e+09 = 0.492The gross margin has been increasing over time, indicating a strong financial performance.2. EPS:   - 2020: 9.690000e+08 / 1.012600e+10 = 0.953   - 2019: 1.583000e+09 / 1.076400e+10 = 1.465   - 2018: 1.127000e+09 / 1.014200e+10 = 1.117   - 2017: 1.347000e+09 / 9.848000e+09 = 0.137   - 2016: 1.543000e+09 / 9.848000e+09 = 0.156The EPS has been increasing over time, indicating a strong financial performance.3. Current Ratio:   - 2020: 2.441000e+09 / 9.222000e+09 = 0.264   - 2019: 1.588000e+09 / 7.821000e+09 = 0.201   - 2018: 1.131000e+09 / 7.265000e+09 = 0.157   - 2017: 8.930000e+08 / 7.244000e+09 = 0.123   - 2016: 8.910000e+08 / 5.020000e+09 = 0.177The current ratio has been increasing over time, indicating a strong financial performance.Based on these financial ratios, the company has been performing well financially and has a strong track record of increasing gross profit and EPS over time. Therefore, I recommend a BUY decision with a confidence score of 80.'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "format_json(output_result['response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "50b16da3-394a-4aeb-8c5d-2a7456d3e0c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved s3://awmgd-prod-finml-sandbox-user/bclarke16/tmp/fs/logs/results - llama - data_quarterly_pit_indu\n",
      "Run Completed!\n"
     ]
    }
   ],
   "source": [
    "ir.save_run({'test':'1234'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eade0d8d-ba3b-4706-a46a-9e76a77ec445",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d4e95d-81d2-428d-9789-02d82b3f374f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fd5cab-e6c8-457a-a6ab-0a66da205511",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efe3e06-50f0-4711-b8d6-a55ce1195aff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96829e27-e611-4533-8ea3-2f8db98d3cb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375dbe05-abfe-45be-a911-e7ff7c27250e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94f5952b-df1a-47ac-b808-81148bdae20a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_helper\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmh\u001b[39;00m\n",
      "File \u001b[0;32m/project/utils/model_helper.py:3\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mboto3\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import utils.model_helper as mh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25404db2-acee-4b0a-83ee-0fef698539b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "helper = mh.ModelHelper('tmp/fs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77bde369-5016-4eb4-bca4-71b8df7d219d",
   "metadata": {},
   "outputs": [],
   "source": [
    "helper.clear_folder('llama')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6a6b91-7e1c-44a1-90bd-7b254f5efee9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bloomberg Lab Python 3",
   "language": "python",
   "name": "remote-jupyterpython"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
