{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d33e342b-edf8-4ce9-8a44-759d241f1fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import modelinference\n",
    "import prompts\n",
    "import importlib\n",
    "import datetime\n",
    "import torch\n",
    "from huggingface_hub import login\n",
    "\n",
    "\n",
    "from accelerate import Accelerator, notebook_launcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1dcf2505-c7f9-440e-91f1-323f2922817a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'modelinference' from '/project/modelinference.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(modelinference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a89aad1-f53b-4d47-840c-5d6c0556f0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log into Huggingface\n",
    "\n",
    "with open('pass.txt') as p:\n",
    "    hf_login = p.read()\n",
    "    \n",
    "hf_login = hf_login[hf_login.find('=')+1:hf_login.find('\\n')]\n",
    "login(hf_login, add_to_git_credential=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5dba1319-9b03-4b71-8e6b-d568d11f233d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b1ac792-d286-4374-977e-a9ae6a0a352b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "run_config = {\n",
    "    'model_hf_id': 'deepseek-ai/DeepSeek-R1-Distill-Qwen-14B',\n",
    "    'model_s3_loc': 'deepseek14Q',\n",
    "    'model_reload': False,\n",
    "    'model_quant': None,\n",
    "    'system_prompt': prompts.SYSTEM_PROMPTS['CoT'],\n",
    "    'multi-gpu':True,\n",
    "    'dataset': 'data_annual_pit_spx',\n",
    "    'data_location': 'data_annual_pit_spx.json'\n",
    "}\n",
    "\n",
    "run_config = {\n",
    "    'model_hf_id': 'Qwen/Qwen2.5-7B-Instruct',\n",
    "    'model_s3_loc': 'qwen',\n",
    "    'model_reload': False,\n",
    "    'model_quant': None,\n",
    "    'system_prompt': prompts.SYSTEM_PROMPTS['BASE'],\n",
    "    'multi-gpu':True,\n",
    "    'dataset': 'data_quarterly_pit_indu',\n",
    "    'data_location': 'data_quarterly_pit_indu.json'\n",
    "}\n",
    "\n",
    "run_config = {\n",
    "    'model_hf_id': 'meta-llama/Llama-3.2-3B-Instruct',\n",
    "    'model_s3_loc': 'llama',\n",
    "    'model_reload': False,\n",
    "    'model_quant': None,\n",
    "    'system_prompt': prompts.SYSTEM_PROMPTS['BASE'],\n",
    "    'multi-gpu':True,\n",
    "    'dataset': 'data_quarterly_pit_indu',\n",
    "    'data_location': 'data_quarterly_pit_indu.json'\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "run_name = f\"{run_config['model_s3_loc']} - {run_config['dataset']}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe94d167-f17d-4a2e-be69-db2210d4bd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ir = modelinference.InferenceRun(run_name, run_config)\n",
    "# ir.run_multi_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18576639-feda-49dd-a949-33b74e581ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_multi_gpu():\n",
    "    ir = modelinference.InferenceRun(run_name, run_config)\n",
    "    ir.run_multi_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a0f3e83-e637-4d70-88a8-39b5a2d6e734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching training on 2 GPUs.\n",
      "llama\n",
      "llama\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "855f45ddb51849bf88cfb9877c4befb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d81cb5c7e7a4ba8b6160cada8e762e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data\n",
      "Memory footprint: 6.4 GB\n",
      "waiting...\n",
      "waiting...\n",
      "starting backtest...starting backtest...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running model...running model...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:08<00:26,  8.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:18<00:54, 18.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:18<00:19,  9.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:23<00:20, 10.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:28<00:09,  9.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:40<00:13, 13.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:46<00:00, 11.75s/it]\n",
      "100%|██████████| 4/4 [00:58<00:00, 14.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished run\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-02-22 18:01:18,093] torch.distributed.elastic.agent.server.api: [WARNING] Received 2 death signal, shutting down workers\n",
      "[2025-02-22 18:01:18,095] torch.distributed.elastic.multiprocessing.api: [WARNING] Closing process 3076 via signal SIGINT\n",
      "[2025-02-22 18:01:18,096] torch.distributed.elastic.multiprocessing.api: [WARNING] Closing process 3077 via signal SIGINT\n",
      "[2025-02-22 18:01:48,114] torch.distributed.elastic.multiprocessing.api: [WARNING] Unable to shutdown process 3076 via 2, forcefully exiting via 9\n"
     ]
    },
    {
     "ename": "SignalException",
     "evalue": "Process 3001 got signal: 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSignalException\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mnotebook_launcher\u001b[49m\u001b[43m(\u001b[49m\u001b[43minference_multi_gpu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_processes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_count\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/kernel/lib/python3.11/site-packages/accelerate/launchers.py:244\u001b[0m, in \u001b[0;36mnotebook_launcher\u001b[0;34m(function, args, num_processes, mixed_precision, use_port, master_addr, node_rank, num_nodes, rdzv_backend, rdzv_endpoint, rdzv_conf, rdzv_id, max_restarts, monitor_interval, log_line_prefix_template)\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_torch_version(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m>=\u001b[39m\u001b[38;5;124m\"\u001b[39m, ELASTIC_LOG_LINE_PREFIX_TEMPLATE_PYTORCH_VERSION):\n\u001b[1;32m    243\u001b[0m         launch_config_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlog_line_prefix_template\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m log_line_prefix_template\n\u001b[0;32m--> 244\u001b[0m     \u001b[43melastic_launch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mLaunchConfig\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mlaunch_config_kwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mentrypoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ProcessRaisedException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m e\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m]:\n",
      "File \u001b[0;32m/opt/kernel/lib/python3.11/site-packages/torch/distributed/launcher/api.py:134\u001b[0m, in \u001b[0;36melastic_launch.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs):\n\u001b[0;32m--> 134\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlaunch_agent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_entrypoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/kernel/lib/python3.11/site-packages/torch/distributed/launcher/api.py:255\u001b[0m, in \u001b[0;36mlaunch_agent\u001b[0;34m(config, entrypoint, args)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    253\u001b[0m     metrics\u001b[38;5;241m.\u001b[39minitialize_metrics(metrics\u001b[38;5;241m.\u001b[39mMetricsConfig(config\u001b[38;5;241m.\u001b[39mmetrics_cfg))\n\u001b[0;32m--> 255\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m     \u001b[38;5;66;03m# records that agent.run() has succeeded NOT that workers have succeeded\u001b[39;00m\n\u001b[1;32m    257\u001b[0m     events\u001b[38;5;241m.\u001b[39mrecord(agent\u001b[38;5;241m.\u001b[39mget_event_succeeded())\n",
      "File \u001b[0;32m/opt/kernel/lib/python3.11/site-packages/torch/distributed/elastic/metrics/api.py:124\u001b[0m, in \u001b[0;36mprof.<locals>.wrap.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    123\u001b[0m     start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 124\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    125\u001b[0m     put_metric(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.success\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1\u001b[39m, group)\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/kernel/lib/python3.11/site-packages/torch/distributed/elastic/agent/server/api.py:736\u001b[0m, in \u001b[0;36mSimpleElasticAgent.run\u001b[0;34m(self, role)\u001b[0m\n\u001b[1;32m    734\u001b[0m shutdown_called: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    735\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 736\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_invoke_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrole\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    737\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_total_execution_time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(time\u001b[38;5;241m.\u001b[39mmonotonic() \u001b[38;5;241m-\u001b[39m start_time)\n\u001b[1;32m    738\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_record_metrics(result)\n",
      "File \u001b[0;32m/opt/kernel/lib/python3.11/site-packages/torch/distributed/elastic/agent/server/api.py:877\u001b[0m, in \u001b[0;36mSimpleElasticAgent._invoke_run\u001b[0;34m(self, role)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    876\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_worker_group\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m!=\u001b[39m WorkerState\u001b[38;5;241m.\u001b[39mINIT\n\u001b[0;32m--> 877\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(monitor_interval)\n\u001b[1;32m    878\u001b[0m     run_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_monitor_workers(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_worker_group)\n\u001b[1;32m    879\u001b[0m     state \u001b[38;5;241m=\u001b[39m run_result\u001b[38;5;241m.\u001b[39mstate\n",
      "File \u001b[0;32m/opt/kernel/lib/python3.11/site-packages/torch/distributed/elastic/multiprocessing/api.py:62\u001b[0m, in \u001b[0;36m_terminate_process_handler\u001b[0;34m(signum, frame)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Termination handler that raises exceptions on the main process.\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \n\u001b[1;32m     55\u001b[0m \u001b[38;5;124;03mWhen the process receives death signal(SIGTERM, SIGINT), this termination handler will\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;124;03mbe terminated.\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     61\u001b[0m sigval \u001b[38;5;241m=\u001b[39m signal\u001b[38;5;241m.\u001b[39mSignals(signum)\n\u001b[0;32m---> 62\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m SignalException(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcess \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mos\u001b[38;5;241m.\u001b[39mgetpid()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m got signal: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msigval\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, sigval\u001b[38;5;241m=\u001b[39msigval)\n",
      "\u001b[0;31mSignalException\u001b[0m: Process 3001 got signal: 2"
     ]
    }
   ],
   "source": [
    "notebook_launcher(inference_multi_gpu, num_processes=torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf4d6235-af59-4924-b54b-72ad749bd686",
   "metadata": {},
   "outputs": [],
   "source": [
    "ir = modelinference.InferenceRun(run_name, run_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7925f016-9392-4142-a9ec-a6872af1bae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = ir.create_all_prompts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14fd8453-b388-488c-b553-aaff3333ea23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "896"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff153540-48a0-4059-acf8-bae25ca9dd78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c5f7290047c4287bc68fd73a09de762",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = ir.load_model_from_storage(ir.model_s3_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dfcdf6bf-07d3-4fb0-87de-034e94e92a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cdf599ad-b6de-4a30-b48a-7c30a97ce88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(ir.model_hf_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a9cff15-9c86-48fd-be61-10bd0d160f83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To make a buy, sell or hold decision, I will compute some common financial ratios.\\n\\n```json\\n{\\n  \"decision\": \"BUY\",\\n  \"confidence score\": 80,\\n  \"reason\": \"Price-to-Earnings ratio is higher than the industry average and the company has shown a steady increase in revenue and net income over the past few years.\"\\n}\\n```\\n\\nI computed the following financial ratios:\\n\\n1. Price-to-Earnings (P/E) ratio:\\n   The P/E ratio is calculated by dividing the current price by the EPS. The current price is 136.188257 and the EPS is 1.640000e+00.\\n   P/E ratio = 136.188257 / 1.640000e+00 = 83.04\\n\\n2. Revenue Growth:\\n   The revenue has been steadily increasing over the past few years.\\n\\n3. Net Income Growth:\\n   The net income has been steadily increasing over the past few years.\\n\\n4. Return on Equity (ROE):\\n   ROE is calculated by dividing net income by total equity.\\n   ROE = 1.012600e+10 / 1.012600e+10 = 1.00\\n\\n5. Debt-to-Equity ratio:\\n   The debt-to-equity ratio is calculated by dividing total liabilities by total equity.\\n   Debt-to-Equity ratio = 3.453300e+10 / 1.012600e+10 = 3.38\\n\\nThe company\\'s P/E ratio is higher than the industry average, which indicates that the stock is overvalued. However, the company has shown a steady increase in revenue and net income over the past few years, which is a positive sign. The return on equity is 1.00, which is a good indicator of the company\\'s profitability. The debt-to-equity ratio is 3.38, which is a bit high but not extremely high.\\n\\nOverall, considering these factors, I am moderately confident in the decision to BUY the stock. However, I am not extremely confident in this decision due to the high debt-to-equity ratio. Therefore, the confidence score is set at 80.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ir.run_model(p1[0]['prompt'],tokenizer,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86f4a03-2196-434b-b5a1-22f2435f9066",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5728ba70-2042-4250-af42-cac37f26eaf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30024d1f-b16b-4214-962c-190106dc2d6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b1782b-e52e-407d-b9d6-2d691cb8fc55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ac4902c-1be1-40ff-a2c0-8fe152641773",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils.modelHelper' from '/project/utils/modelHelper.py'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import utils.modelHelper as mh\n",
    "import importlib\n",
    "importlib.reload(mh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9766f6e8-0b50-43d1-bc2a-9a50017646f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "helper = mh.ModelHelper('tmp/fs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03a20d35-c77e-43d6-b5fc-fd84ca9ebe45",
   "metadata": {},
   "outputs": [],
   "source": [
    "helper.clear_folder('llama')\n",
    "#helper.clear_folder(f'Data/{run_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6a8bc7a-6a81-4ef5-9467-6f9f4910143a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0797c36d-cfc1-4470-8741-e5e3e6a84acf",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ROOT_DIR' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mROOT_DIR\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ROOT_DIR' is not defined"
     ]
    }
   ],
   "source": [
    "print(os.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99608ae3-8c19-43ae-b787-7dcdbf33df79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/project'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.abspath(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1703e1a2-23da-4727-99ba-430654da612f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bloomberg Lab Python 3",
   "language": "python",
   "name": "remote-jupyterpython"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
