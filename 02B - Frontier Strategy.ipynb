{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7e8b137-5ee8-4669-92d3-4d3373d7366a",
   "metadata": {},
   "source": [
    "# Frontier Models\n",
    "\n",
    "This section uses AWS Bedrock to run inference tests using the Claude and Open AI models. We use LangChain and Python multi-threading to run the inference tasks and quickly loop through all of the prompts to generate our output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a618881-9e45-442b-b7d3-f15f27b8dd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "import botocore\n",
    "import datetime\n",
    "import importlib\n",
    "import prompts\n",
    "from tqdm import tqdm\n",
    "\n",
    "from prompts import SYSTEM_PROMPTS\n",
    "from IPython.display import Markdown, display\n",
    "import constructors.langchain_strategy as ls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0aba175d-b883-4801-9810-aeb112234fa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'constructors.langchain_strategy' from '/project/constructors/langchain_strategy.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(prompts)\n",
    "importlib.reload(ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5d6ee4b-3c8d-414c-addc-18f7a78bad05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.38.8'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# boto3 must be version 1.34.51 or higher\n",
    "boto3.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17ce96a8-e4bd-41fd-ac8a-b97dff2596e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bedrock client initialise\n",
    "config = botocore.config.Config(read_timeout=1000)\n",
    "boto3_bedrock = boto3.client('bedrock-runtime',config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad99a440-fba1-4d96-8a91-b572317b2e29",
   "metadata": {},
   "source": [
    "## Strategy Construction for Frontier Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47d815fa-1101-4ccf-a0ac-95aab83a986b",
   "metadata": {},
   "outputs": [],
   "source": [
    "frontier = ls.FrontierRun(run_name='Claude 3.7',\n",
    "                       model_id='us.anthropic.claude-3-7-sonnet-20250219-v1:0',\n",
    "                       dataset_id='dow_quarterly_ltm_v3.json',system_prompt=prompts.SYSTEM_PROMPTS['BASE_CLAUDE']['prompt'],boto3_bedrock=boto3_bedrock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "261d4087-feb6-4fd8-a75b-e422527e7767",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = frontier.setup_prompts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33c8ce45-6d62-4a36-bc0e-290a1077c464",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:10<00:00,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unable to save file - you can access via self.output to cache your results from the backtest!\n",
      "unable to save file - you can access via self.output to cache your results from the backtest!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "frontier.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39709263-aeac-4c2a-9209-9392bc2d249d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefcb8bc-fa62-4d80-9bc0-567ddca1e9e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a7274a-ba77-42d7-9578-03e4da13e8cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ed8d594a-7c2a-455c-b9fc-1be0d2a4a7ad",
   "metadata": {},
   "source": [
    "## Initial Bedrock Test\n",
    "This is an initial run of Bedrock with Anthropic to see how it responds to the financial analysis task as a single model run. The below code was used for the development of the strategy construction module for LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "891eec29-a7b1-4d3d-aa45-2bf7b0deba62",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# set the model\n",
    "model = 'us.anthropic.claude-3-7-sonnet-20250219-v1:0'\n",
    "# load prompts into memory\n",
    "with open('Data/prompts.json', 'rb') as f:\n",
    "    prompts = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa45f14b-0da6-4f38-95d6-7b255b38f20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_claude_request(prompt: str) -> str:\n",
    "    \n",
    "    native_request = {\n",
    "        \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "        \"max_tokens\": 5000,\n",
    "        \"temperature\": 0.7,\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\":\"user\",\n",
    "                \"content\": [{\"type\":\"text\", \"text\":prompt}]\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    return json.dumps(native_request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c054649f-2415-4636-bd4e-1f9604b37836",
   "metadata": {},
   "outputs": [],
   "source": [
    "GUARDRAIL_ID = os.environ['BEDROCK_GUARDRAIL_ID']\n",
    "GUARDRAIL_VERSION = os.environ['BEDROCK_GUARDRAIL_VERSION']\n",
    "\n",
    "model_id = model\n",
    "\n",
    "\n",
    "def invoke_model_claude(prompt: dict, model_id: str) -> str:\n",
    "    \"\"\"Invoke the model using Bedrock. This is specifically designed for Anthropic models\"\"\"\n",
    "    accept = 'application/json'\n",
    "    contentType = 'application/json'\n",
    "\n",
    "    # set up the request\n",
    "    request = setup_claude_request(prompt)\n",
    "    try:\n",
    "        \n",
    "        response = boto3_bedrock.invoke_model(\n",
    "            body=request, \n",
    "            modelId=model_id, \n",
    "            accept=accept, \n",
    "            contentType=contentType,\n",
    "            trace = \"ENABLED\"\n",
    "        )\n",
    "        response_body = json.loads(response.get('body').read())\n",
    "        return response_body.get('content')[0].get('text') #Anthropic response template\n",
    "    \n",
    "    except botocore.exceptions.ClientError as error:\n",
    "        \n",
    "        if error.response['Error']['Code'] == 'AccessDeniedException':\n",
    "               print(f\"\\x1b[41m{error.response['Error']['Message']}\\\n",
    "                    \\nTo troubeshoot this issue please refer to the following resources.\\\n",
    "                     \\nhttps://docs.aws.amazon.com/IAM/latest/UserGuide/troubleshoot_access-denied.html\\\n",
    "                     \\nhttps://docs.aws.amazon.com/bedrock/latest/userguide/security-iam.html\\x1b[0m\\n\")\n",
    "            \n",
    "        else:\n",
    "            raise error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c7b840-2df8-4216-b882-cc3f169b95d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = invoke_model_claude(prompt, model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603abaa6-1d04-4066-b9bb-4792c1d5df1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9947ce3f-67b9-4064-87fe-d193d6b4d774",
   "metadata": {},
   "source": [
    "## LangChain version\n",
    "This is the langgraph version in prep for multi-agentic AI system"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76af00d1-d2de-4061-9b93-69fb3a06482b",
   "metadata": {},
   "source": [
    "### Run Inference Loop for Dow Jones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81086c8d-97db-42bf-8f2e-7dc8ad39828c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnableSequence\n",
    "from langchain_core.rate_limiters import InMemoryRateLimiter\n",
    "\n",
    "from langchain_aws import ChatBedrock\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a599c81-f765-4036-8dda-50b542167e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the LLM in Bedrock\n",
    "rate_limiter = InMemoryRateLimiter(\n",
    "    requests_per_second=50,\n",
    "    check_every_n_seconds=1,\n",
    "    max_bucket_size=10,\n",
    ")\n",
    "\n",
    "llm = ChatBedrock(\n",
    "    client = boto3_bedrock,\n",
    "    #model = \"us.meta.llama3-1-70b-instruct-v1:0\",\n",
    "    model = 'us.anthropic.claude-3-7-sonnet-20250219-v1:0',\n",
    "    temperature = 0.5,#0.7,\n",
    "    max_tokens=4000,\n",
    "    rate_limiter = rate_limiter\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd5420b8-734e-46c3-b56c-003464260c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = SYSTEM_PROMPTS['COT_EARN_CLAUDE']['prompt']\n",
    "prompt_template = PromptTemplate.from_template(system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e9e9101-c974-4a3a-89da-70dd787bc74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(prompt: dict, llm: RunnableSequence) -> dict:\n",
    "    prompt_in = prompt_template.format(financials=prompt['prompt'][1]['content'])\n",
    "    output = llm.invoke(prompt_in)\n",
    "    decision_dict = {\n",
    "        'date': prompt['date'],\n",
    "        'security': prompt['security'],\n",
    "        'response': output\n",
    "    }\n",
    "    return decision_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9e29e7d-dcaf-4e51-9337-44ead6112176",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['financials'], input_types={}, partial_variables={}, template='You are a financial analyst. Use the following income statement, balance sheet and cash flow to make a decision on if earnings will increase over the next financial period. Think step-by-step through the financial statement analysis workflow. Your report should have the following sections: 1. Analysis of current profitability, liquidity, solvency and efficiency ratios; 2. time-series analysis across the ratios; 3. Analysis of financial performance; 4. Stock Price analysis; 5. Decision Analysis looking at the positive and negative factors as well as the weighting in the final decision; 6. Final Decision. Make your decision only on the datasets. Explain your reasons in less than 250 words. Indicate the magnitude of the increase or decrease. Provide a confidence score for how confident you are of the decision. If you are not confident then lower the confidence score. {financials}')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prompt_template.format(financials=prompts[0]['prompt'][1]['content'])\n",
    "prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1a8c07e-0354-4e38-9dc5-4fa33195edff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'date': '2020-02-06',\n",
       " 'security': 'MMM UN Equity',\n",
       " 'response': AIMessage(content=\"# Financial Analysis: Earnings Forecast\\n\\nBased on a thorough analysis of the provided financial statements, I will assess whether earnings are likely to increase in the next financial period.\\n\\n## Key Observations\\n\\n### Revenue and Profitability Trends\\n- Revenue shows slight growth from t-1 to t (1.5% increase from $7.99B to $8.11B)\\n- However, operating income declined significantly from $2.01B in t-1 to $1.33B in t (34% decrease)\\n- Net income decreased from $1.58B in t-1 to $969M in t (38.8% decrease)\\n- EPS declined from $2.72 (diluted) to $1.66 (39% decrease)\\n\\n### Cost Structure\\n- Operating expenses increased substantially from $1.79B in t-1 to $2.46B in t (37.3% increase)\\n- SG&A expenses rose from $1.46B to $1.94B (33.3% increase)\\n- R&D expenses increased from $443M to $521M (17.6% increase)\\n- Abnormal losses of $348M in period t compared to gains of $112M in t-1\\n\\n### Balance Sheet Analysis\\n- Cash and equivalents decreased dramatically from $7.73B in t-1 to $2.35B in t (69.6% decrease)\\n- Total assets increased from $42.55B to $44.66B (5.0% increase)\\n- Short-term debt increased from $2.20B to $3.06B (39.1% increase)\\n- Total liabilities increased from $31.79B to $34.53B (8.6% increase)\\n- Total equity decreased from $10.76B to $10.13B (5.9% decrease)\\n\\n### Efficiency and Margins\\n- Gross profit margin decreased from 47.6% to 46.7%\\n- Operating margin decreased from 25.2% to 16.3%\\n- Net profit margin decreased from 19.8% to 11.9%\\n\\n## Analysis and Forecast\\n\\nSeveral concerning trends suggest earnings challenges ahead:\\n\\n1. **Declining Profitability**: Despite modest revenue growth, there's a significant decline in operating income and net income, indicating deteriorating operational efficiency.\\n\\n2. **Rising Costs**: The substantial increase in operating expenses, especially SG&A costs, is outpacing revenue growth, compressing margins.\\n\\n3. **Increased Debt**: Short-term debt has increased while cash reserves have dramatically decreased, suggesting potential liquidity pressure and higher interest expenses going forward.\\n\\n4. **Abnormal Losses**: The company recorded significant abnormal losses in period t, which may indicate restructuring or other operational challenges.\\n\\n5. **Cash Flow Concerns**: The dramatic reduction in cash reserves suggests either major investments, debt repayments, or operational cash flow issues.\\n\\n## Earnings Forecast\\n\\nBased on the financial data analysis, I forecast that earnings will **decrease** in the next financial period by approximately **15-20%**.\\n\\nThe primary drivers for this forecast include:\\n- Continuing pressure on operating margins due to elevated SG&A and R&D expenses\\n- Increased interest expenses from higher debt levels\\n- Reduced financial flexibility due to lower cash reserves\\n- Potential continuation of restructuring costs (evidenced by abnormal losses)\\n- Modest revenue growth insufficient to offset rising costs\\n\\n## Confidence Score: 7/10\\n\\nMy confidence is moderate because:\\n- The data shows clear negative trends in profitability metrics\\n- However, without information on industry conditions, market dynamics, or management's strategic initiatives, there's uncertainty about potential turnaround efforts\\n- The significant cash reduction could indicate either concerning cash burn or strategic investments that might yield future returns\\n- The restructuring expenses might be temporary and could lead to improved efficiency in future periods\\n\\nThe company appears to be in a transitional period with significant cost pressures, which typically takes more than one period to resolve, supporting the forecast of continued earnings pressure in the near term.\", additional_kwargs={'usage': {'prompt_tokens': 4971, 'completion_tokens': 907, 'total_tokens': 5878}, 'stop_reason': 'end_turn', 'thinking': {}, 'model_id': 'us.anthropic.claude-3-7-sonnet-20250219-v1:0', 'model_name': 'us.anthropic.claude-3-7-sonnet-20250219-v1:0'}, response_metadata={'usage': {'prompt_tokens': 4971, 'completion_tokens': 907, 'total_tokens': 5878}, 'stop_reason': 'end_turn', 'thinking': {}, 'model_id': 'us.anthropic.claude-3-7-sonnet-20250219-v1:0', 'model_name': 'us.anthropic.claude-3-7-sonnet-20250219-v1:0'}, id='run-c864248c-6171-4c5b-9035-01a82de88c23-0', usage_metadata={'input_tokens': 4971, 'output_tokens': 907, 'total_tokens': 5878})}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_model(prompts[0], llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a9f2a37-8afb-48dd-b732-184b2d97abc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.83 s, sys: 652 ms, total: 7.49 s\n",
      "Wall time: 6min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# This creates the initial response - run this in parallel with 100 executors\n",
    "data = []\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=100) as executor:\n",
    "    futures = [executor.submit(run_model, prompt, llm) for prompt in prompts]\n",
    "    data = [f.result() for f in futures]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ec4d369-cd7c-4ede-8b04-c529fa95bdb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "896"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e62edbc-3a9a-42a1-b479-ba85f26faec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_output = [{'date': i['date'], \n",
    "             'security': i['security'], \n",
    "             'response': i['response'].content} \n",
    "            for i in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "09cecfaa-4406-41e5-ac20-bf9bbf1d7d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Data/Results - Bedrock2.json', 'w') as f:\n",
    "    json.dump(cleaned_output, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e6bb21-0edc-430c-a641-54ee4c56df08",
   "metadata": {},
   "source": [
    "## Convert to JSON format\n",
    "This is needed to run the trade analytics and compare to other LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bd74df7f-b466-4586-b27d-24e08e18af09",
   "metadata": {},
   "outputs": [],
   "source": [
    "rate_limiter = InMemoryRateLimiter(\n",
    "    requests_per_second=10,\n",
    "    check_every_n_seconds=1,\n",
    "    max_bucket_size=10,\n",
    ")\n",
    "\n",
    "llm = ChatBedrock(\n",
    "    client = boto3_bedrock,\n",
    "    #model = \"us.meta.llama3-1-70b-instruct-v1:0\",\n",
    "    model = 'us.anthropic.claude-3-7-sonnet-20250219-v1:0',\n",
    "    temperature = 0.5,#0.7,\n",
    "    max_tokens=4000,\n",
    "    rate_limiter = rate_limiter\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7b9d4083-5cbc-40eb-86d1-64bf773a8eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 1: Set up the structured output\n",
    "# class FinancialOutput(BaseModel):\n",
    "#     \"\"\"Answer to the users question along with justification\"\"\"\n",
    "#     decision: str = Field(..., description=\"Final Decision: BUY, SELL or HOLD\")\n",
    "#     reason: str = Field(..., description=\"Summary of the final decision\")\n",
    "#     confidence: int = Field(..., description=\"How confident you are of the decision\")\n",
    "\n",
    "# with open('Results/Earnings/results - deepseek - cot - 2025-03-30 .828629.json', 'rb') as f:\n",
    "#     raw_output = json.load(f)\n",
    "\n",
    "class FinancialOutput(BaseModel):\n",
    "    \"\"\"Answer to the users question along with justification\"\"\"\n",
    "    direction: str = Field(..., description=\"earnings will increase or decrease or stay flat\")\n",
    "    magnitude: str = Field(..., description=\"size of the increase or decrease\")\n",
    "    reason: str = Field(..., description=\"Summary of the final decision\")\n",
    "    confidence: str = Field(..., description=\"How confident you are of the decision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1bbf2bd3-7e9f-46f5-9bd6-b3ba57b1a4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_output = raw_output['results']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "315e70b5-b689-40d1-8983-10b5a5fea794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 2: set up the system prompt and set the structured output format\n",
    "system_prompt = \"You are an assistant to a financial analyst. You are responsible for formatting the documents that the analyst produces into a machine readable format. Use only the information provided in the context. Convert it into the structured output. Do not add anything to the analysts report and do not change the recommendation. Do not hallucinate. Find the investment decision. Find the conclusion. Add all of the wording of the thought process into the steps section. context: {context}\"\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(system_prompt)\n",
    "structured_llm = llm.with_structured_output(FinancialOutput)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "10be12b4-c2b9-4b8c-a5f1-a2e430589a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 3: Set up the function to call in each thread\n",
    "# def run_cleanup(prompt: dict, llm: RunnableSequence) -> dict:\n",
    "#     thought_process = prompt['response']\n",
    "#     prompt_in = prompt_template.format(context=thought_process)\n",
    "#     response = llm.invoke(prompt_in)\n",
    "#     final_dict = {\n",
    "#         'date': prompt['date'],\n",
    "#         'security': prompt['security'],\n",
    "#         'response': {\n",
    "#             'decision': response.decision,\n",
    "#             'reason': response.reason,\n",
    "#             'confidence': response.confidence,\n",
    "#             'thought_process': thought_process\n",
    "#         }\n",
    "#     }\n",
    "#     return final_dict\n",
    "\n",
    "def run_cleanup(prompt: dict, llm: RunnableSequence) -> dict:\n",
    "    thought_process = prompt['response']\n",
    "    prompt_in = prompt_template.format(context=thought_process)\n",
    "    response = llm.invoke(prompt_in)\n",
    "    final_dict = {\n",
    "        'date': prompt['date'],\n",
    "        'security': prompt['security'],\n",
    "        'response': {\n",
    "            'analyst_direction': response.direction,\n",
    "            'analyst_magnitude': response.magnitude,\n",
    "            'reason': response.reason,\n",
    "            'confidence': response.confidence,\n",
    "            'thought_process': thought_process\n",
    "        }\n",
    "    }\n",
    "    return final_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a1a2d191-2abf-4987-9663-df423d4b1ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 4: \n",
    "\n",
    "responses = []\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:\n",
    "    futures = [executor.submit(run_cleanup, prompt, structured_llm) for prompt in cleaned_output]\n",
    "    responses = [f.result() for f in futures]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d4f69352-d175-4245-929d-88f65ac75ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # STEP 5: convert to the correct format\n",
    "final_json = {\n",
    "    'run_date': str(datetime.datetime.now()),\n",
    "    'system_prompt': SYSTEM_PROMPTS['COT_EARN_CLAUDE']['prompt'],\n",
    "    'dataset': 'data_quarterly_pit_indu_blended',\n",
    "    'model': model,\n",
    "    'results': responses\n",
    "}\n",
    "\n",
    "# final_json = {\n",
    "#     'run_date': str(datetime.datetime.now()),\n",
    "#     'system_prompt': raw_output['system_prompt'],\n",
    "#     'dataset': raw_output['dataset'],\n",
    "#     'model': raw_output['model'],\n",
    "#     'results': responses\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e4c8aa7d-757f-4ed1-93b9-f141f4a44e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 6: Save the results \n",
    "with open(f'Results/results - Deepseek - COT C -{str(datetime.datetime.now())}.json', 'w') as f:\n",
    "    json.dump(final_json, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bloomberg Lab Python 3",
   "language": "python",
   "name": "remote-jupyterpython"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
