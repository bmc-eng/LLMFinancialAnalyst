{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f7b5da4-443e-4c6c-bdd8-427ac5b1ba47",
   "metadata": {},
   "source": [
    "# Open Source Models\n",
    "\n",
    "In this notebook we use the models_helper to request all of the models from Huggingface that we will be using as part of the project. This saves the models in Bloomberg Lab S3 storage and makes requesting of them easier during the multi-GPU inference tasks. It means that they do not have to be downloaded by each GPU.\n",
    "\n",
    "The models we will access are:\n",
    "\n",
    "- Llama 3.2 3B - meta-llama/Llama-3.2-3B-Instruct\n",
    "- DeepSeek R1 Qwen 7B - deepseek-ai/DeepSeek-R1-Distill-Qwen-7B\n",
    "- DeepSeek R1 Qwen 14B - deepseek-ai/DeepSeek-R1-Distill-Qwen-14B\n",
    "- Qwen 2.5 3B - Qwen/Qwen2.5-3B-Instruct\n",
    "- Qwen 2.5 7B - Qwen/Qwen2.5-7B-Instruct\n",
    "\n",
    "We also tried to run: \n",
    "- DeepSeek R1 Qwen 32B - deepseek-ai/DeepSeek-R1-Distill-Qwen-32B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba650f2d-9c02-498a-8593-afaa9478621a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.model_helper import ModelHelper\n",
    "from huggingface_hub import login\n",
    "from transformers import BitsAndBytesConfig\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16877027-6c51-427b-b89d-0751b479d75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_requester = ModelHelper('tmp/fs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "201dc861-a7df-4822-b598-dccbea5d2ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log into Huggingface with login credentials. .env can be used as well\n",
    "with open('pass.txt') as p:\n",
    "    hf_login = p.read()\n",
    "    \n",
    "hf_login = hf_login[hf_login.find('=')+1:hf_login.find('\\n')]\n",
    "login(hf_login, add_to_git_credential=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3747472-aad5-412d-ba69-f7735154504e",
   "metadata": {},
   "source": [
    "### Llama 3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fa3a35d-832a-49b7-8ed1-7933e17f6ab7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d5431fb61494988840617eab8fc2e65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/878 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a0d3e29294e42038e424e2f50d13e66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/20.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a199748168da4602a7f79bfbe4544246",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4350f22596f34682bf84cf68f401f6da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "663233593fd54410a69e943d4c8562d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/1.46G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fab0bacc9fae45328ef461c9d601c4d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f479572946bb47a8bd88407cbd7fdd1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/189 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded: /tmp//llama\n"
     ]
    }
   ],
   "source": [
    "# request the model and save in temp folder under name llama to retrieve later\n",
    "model_requester.get_model_and_save(model_id='meta-llama/Llama-3.2-3B-Instruct', \n",
    "                                   model_name='llama', model_tmp_location='/tmp/',\n",
    "                                   use_quantization=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f317f30b-75e1-4104-9b8f-0ac06419d42d",
   "metadata": {},
   "source": [
    "### DeepSeek R1 Qwen 7B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c22dd02b-f4aa-4c81-92e6-927c4ebf080c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21fe3eb69a2242378b7364ba79eae7b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/680 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "347149ab1464482fa393cf405db5b337",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/28.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d362d5788fa34325958d4a02da3e70e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb78dc5bd0b5480394af7741d611c054",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-000002.safetensors:   0%|          | 0.00/8.61G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7161072d3c984390988de3711acd6f68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-000002.safetensors:   0%|          | 0.00/6.62G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6c1f72c2ea943c6af557ecac37cc3d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f6bcd46edcb43a3a58d5baa27fec8e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/181 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded: /tmp//deepseek7B\n"
     ]
    }
   ],
   "source": [
    "# Use Quantization to reduce memory size\n",
    "quant_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    bnb_4bit_quant_type=\"nf4\"\n",
    "\n",
    ")\n",
    "\n",
    "# request the model and save in temp folder \n",
    "model_requester.get_model_and_save(model_id='deepseek-ai/DeepSeek-R1-Distill-Qwen-7B', \n",
    "                                   model_name='deepseek7B', model_tmp_location='/tmp/',\n",
    "                                   use_quantization=True,\n",
    "                                  quant_config=quant_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfe1bd6-135f-4f1a-973b-7c831d36c812",
   "metadata": {},
   "source": [
    "### DeepSeek R1 Qwen 14B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23803fd4-0be3-4a99-b4dc-377142f5d38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    bnb_4bit_quant_type=\"nf4\"\n",
    "\n",
    ")\n",
    "\n",
    "# request the model and save in temp folder \n",
    "model_requester.get_model_and_save(model_id='deepseek-ai/DeepSeek-R1-Distill-Qwen-14B', \n",
    "                                   model_name='deepseek14Q', model_tmp_location='/tmp/',\n",
    "                                   use_quantization=True,\n",
    "                                  quant_config=quant_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cdb9029-9c9f-4c21-b59a-250924bcc18e",
   "metadata": {},
   "source": [
    "### Qwen 2.5 3B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b237f5f7-f297-4338-a8dc-c0eb04a97e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    bnb_4bit_quant_type=\"nf4\"\n",
    "\n",
    ")\n",
    "\n",
    "# request the model and save in temp folder \n",
    "model_requester.get_model_and_save(model_id='Qwen/Qwen2.5-3B-Instruct', \n",
    "                                   model_name='qwen3b', model_tmp_location='/tmp/',\n",
    "                                   use_quantization=True,\n",
    "                                  quant_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5d0ded-41ff-4108-bb48-0a748d63ebbe",
   "metadata": {},
   "source": [
    "### Qwen 2.5 7B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9152852-7d7e-4fb8-b089-8b9a0ffec32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# request the model and save in temp folder \n",
    "model_requester.get_model_and_save(model_id='Qwen/Qwen2.5-7B-Instruct', \n",
    "                                   model_name='qwen', model_tmp_location='/tmp/',\n",
    "                                   use_quantization=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bloomberg Lab Python 3",
   "language": "python",
   "name": "remote-jupyterpython"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
