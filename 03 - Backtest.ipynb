{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de3912eb-612a-499e-9c4e-edee06488a45",
   "metadata": {},
   "source": [
    "# Backtest the strategies\n",
    "\n",
    "Use an LLM to go through and predict the buy/ sell/ hold recommendation for the company for the given date. Steps needed:\n",
    "\n",
    "1. Load the LLM - use DeepSeek R1 Qwen model at 7B parameters first and try the quantised models next\n",
    "2. Step through each data and each financial statement to get a result\n",
    "3. Log the results in a file and save to S3 (will need a logging file to save to S3 and resume in case of kernel crash)\n",
    "4. Need a backtesting framework to apply the results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d93b98-69cc-4462-a0f4-a17f2f95dd3f",
   "metadata": {},
   "source": [
    "## Load libraries needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3af882af-086b-45c8-a773-215a83e2a864",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "from s3fs import S3FileSystem\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from huggingface_hub import login\n",
    "import torch\n",
    "from accelerate import Accelerator\n",
    "\n",
    "import pandas as pd\n",
    "from IPython.display import Markdown, display\n",
    "from ipywidgets import IntProgress, Label, HBox\n",
    "\n",
    "from helper import get_s3_folder\n",
    "import s3Helpers\n",
    "import company_data\n",
    "import prompts\n",
    "from s3Helpers import S3ModelHelper, Logger\n",
    "from prompts import SYSTEM_PROMPTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4fb4ed3-be43-40fa-bd65-13d7588c9c3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'prompts' from '/project/prompts.py'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(company_data)\n",
    "importlib.reload(s3Helpers)\n",
    "importlib.reload(prompts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb94ecb-4b18-41c5-8849-696b395f4de1",
   "metadata": {},
   "source": [
    "## Load the LLM\n",
    "\n",
    "Models to test:\n",
    "- Qwen (Qwen/Qwen2.5-7B-Instruct)\n",
    "- Llama (meta-llama/Llama-3.2-7B-Instruct)\n",
    "- DeepSeek (deepseek-ai/DeepSeek-R1-Distill-Qwen-14B)\n",
    "- DeepSeek Quantized (deepseek-ai/DeepSeek-R1-Distill-Qwen-32B) quantized to 4 bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd948d2f-1791-4313-bedc-f9ed31aa63a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log into Huggingface\n",
    "\n",
    "with open('pass.txt') as p:\n",
    "    hf_login = p.read()\n",
    "    \n",
    "hf_login = hf_login[hf_login.find('=')+1:hf_login.find('\\n')]\n",
    "login(hf_login, add_to_git_credential=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4aaea478-b1ed-420b-bd8f-0851b1c6e3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Quantization \n",
    "quant_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    bnb_4bit_quant_type=\"nf4\"\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c2bb562-aec7-44a3-87a7-c509839c6dc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9e653838bf64350ae4eefd49c6042f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/664 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e874a6f309142c0bd3e6f87e1116a9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/48.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d13f2bf1de4845548cee439f07f1ad81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f07ff5617ed4125936fcef144557bfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-000004.safetensors:   0%|          | 0.00/8.71G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "539b99c8254a4a428f77afbf5714c92d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-000004.safetensors:   0%|          | 0.00/8.67G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5d2f03fc83c46e889710cb8b6575944",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-000004.safetensors:   0%|          | 0.00/8.67G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23e1b776451442f48d8c0a9c7ee5ec58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-000004.safetensors:   0%|          | 0.00/3.49G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fc97d1916db4a9bb700832b11e3b7eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2577e62a9fb4470da6b6ba17c30e2d19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/181 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8af79624065347719c089019d83245a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/3.07k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9c17717980742b8b72d25c984c732d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/7.03M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory footprint: 9.7 GB\n"
     ]
    }
   ],
   "source": [
    "# Flag to download from Huggingface again or use stored model\n",
    "USE_HF = True\n",
    "USE_QUANTIZATION = True\n",
    "\n",
    "model_id = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-14B\"\n",
    "model_id_s3 = 'deepseek14'\n",
    "\n",
    "\n",
    "if USE_HF:\n",
    "   \n",
    "    # pipeline = transformers.pipeline(\n",
    "    #     \"text-generation\",\n",
    "    #     model=model_id,\n",
    "    #     model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
    "    #     device_map=\"auto\",\n",
    "    # )\n",
    "    \n",
    "    if USE_QUANTIZATION:\n",
    "        model = AutoModelForCausalLM.from_pretrained(model_id, device_map='auto', quantization_config=quant_config)\n",
    "    else:\n",
    "        model = AutoModelForCausalLM.from_pretrained(model_id, device_map='auto', torch_dtype=torch.bfloat16)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "else:\n",
    "    model_helper = s3Helpers.S3ModelHelper(s3_sub_folder='tmp/fs')\n",
    "    if USE_QUANTIZATION:\n",
    "        model = model_helper.load_model(model_id_s3, quant_config)\n",
    "    else:\n",
    "        model = model_helper.load_model(model_id_s3)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "    # pipeline = transformers.pipeline(\n",
    "    #     \"text-generation\",\n",
    "    #     model=model,\n",
    "    #     tokenizer=tokenizer,\n",
    "    #     model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
    "    #     device_map=\"auto\",\n",
    "    # )\n",
    "    model_helper.clear_folder(model_id_s3)\n",
    "\n",
    "print(f\"Memory footprint: {model.get_memory_footprint() / 1e9:,.1f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6029e0fb-a198-4dea-b42b-d506c783a7f4",
   "metadata": {},
   "source": [
    "## Load Financial PIT dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eaa01423-1a10-4b83-a25c-ebf18b932470",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load from S3 using the helper file\n",
    "filename = 'data_annual_pit_indu.json' #'data_quarterly_pit_indu.json'\n",
    "sec_helper = company_data.SecurityData('tmp/fs',filename)\n",
    "all_data = sec_helper.get_all_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "407bc769-45aa-44b4-96c8-24d14ca19040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# USE WHILE DEVELOPING to\n",
    "importlib.reload(company_data)\n",
    "sec_helper = company_data.SecurityData('tmp/fs',filename, all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e386e4c6-a489-46f2-b023-f58fb4313728",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "232"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sec_helper.total_securities_in_backtest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8376dba1-9ecc-4856-8dcc-f8f03ad0827f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['JNJ UN Equity', 'WMT UN Equity'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data['2020-02-18'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08ad27ae-6370-4efd-a9a2-185c13992ea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-02-18</th>\n",
       "      <td>33.330000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-18</th>\n",
       "      <td>33.220000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-18</th>\n",
       "      <td>34.393333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-18</th>\n",
       "      <td>33.620000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-18</th>\n",
       "      <td>36.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-18</th>\n",
       "      <td>38.240000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-08-18</th>\n",
       "      <td>37.663333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-09-18</th>\n",
       "      <td>39.053333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-18</th>\n",
       "      <td>39.713333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-18</th>\n",
       "      <td>40.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-18</th>\n",
       "      <td>39.953333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-18</th>\n",
       "      <td>38.320000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-18</th>\n",
       "      <td>39.876667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Price\n",
       "Date                 \n",
       "2019-02-18  33.330000\n",
       "2019-03-18  33.220000\n",
       "2019-04-18  34.393333\n",
       "2019-05-18  33.620000\n",
       "2019-06-18  36.550000\n",
       "2019-07-18  38.240000\n",
       "2019-08-18  37.663333\n",
       "2019-09-18  39.053333\n",
       "2019-10-18  39.713333\n",
       "2019-11-18  40.083333\n",
       "2019-12-18  39.953333\n",
       "2020-01-18  38.320000\n",
       "2020-02-18  39.876667"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sec_helper.get_security_statement('2020-02-18','JNJ UN Equity','px') #AXP UN Equity2020-04-24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0a5016b-31ec-4365-aef4-c8db0c063c0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You are a financial analyst tasked with analyzing the financial statements of a company to predict the direction of future earnings.Follow the steps below to perform the analysis. 1. Identify notable changes in the balance sheet and income statement. 2. Compute key financial ratios to understand the health of the company. State the formula before calculating. Compute profitability ratios, leverage ratios, liquidity ratios and efficiency ratios. 3. Interpret each of the ratios. 4. Predict the direction of future earnings in JSON format with a clear recommendation and size of the increase or decrease: {'earnings':'INCREASE', 'magnitude':'LARGE'} or {'earnings':'DECREASE','SMALL'} 5. Provide a rational in less than 250 words. Company Financial Statements: \""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_prompt = prompts.SYSTEM_PROMPTS['CoT']['prompt']\n",
    "system_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eaed3958-56ad-43ca-92e1-17b6c3698e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = sec_helper.get_prompt('2020-02-18','JNJ UN Equity', system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bc4ce7f3-45c8-4cd3-89fc-92044d7a9e60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6590"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = tokenizer.apply_chat_template(prompt, tokenize=True, add_generation_prompt=True)\n",
    "len(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30342446-1709-4731-bb97-37a1a94dd62a",
   "metadata": {},
   "source": [
    "## Run an example in LLM\n",
    "\n",
    "Run into out of memory problem - Potential fixes:\n",
    "1. reduce size of model (quantize)\n",
    "2. explore multi-gpu\n",
    "3. reduce tokens\n",
    "\n",
    "https://saturncloud.io/blog/how-to-solve-cuda-out-of-memory-error-in-pytorch/\n",
    "\n",
    "https://huggingface.co/docs/accelerate/usage_guides/distributed_inference\n",
    "\n",
    "https://medium.com/@geronimo7/llms-multi-gpu-inference-with-accelerate-5a8333e4c5db\n",
    "\n",
    "Problem with splitting a single prompt into multiple gpus to calculate the result. Tensor parallelism - https://huggingface.co/docs/transformers/main/en/perf_train_gpu_many#tensor-parallelism\n",
    "\n",
    "nvidia-smi will show available GPUs on the system.\n",
    "\n",
    "### Run 1\n",
    "Model used: Llama 3.2 3B Instruct (meta-llama/Llama-3.2-3B-Instruct) \n",
    "No quantisation. Run in 5.5 hours on 1 A10G GPU on 896 security/ date combinations. The data is stored in log files in the project for further analysis. The base prompt was used with no chain of thought.\n",
    "\n",
    "### Run 2\n",
    "Model used: Deepseek R1 14B Qwen (deepseek-ai/DeepSeek-R1-Distill-Qwen-14B)\n",
    "No quantisation. Run took over 24 hours to complete on 2 A10G GPU on 896 security/ date combinations. The data is stored in log files in the project for further analysis. The base prompt was used with no chain of thought."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d04287fc-33e1-4934-8647-80000236de97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(prompt, tokenizer, model):\n",
    "    tokens = tokenizer.apply_chat_template(prompt, tokenize=False, add_generation_prompt=True)\n",
    "    model_inputs = tokenizer([tokens], return_tensors='pt').to('cuda')\n",
    "    generated_ids = model.generate(**model_inputs, pad_token_id=tokenizer.eos_token_id, max_new_tokens=5000)\n",
    "    parsed_ids = [\n",
    "        output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "    ]\n",
    "    return tokenizer.batch_decode(parsed_ids, skip_special_tokens=True)[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cad81f0d-e28a-4c9e-9380-6b4d09b9b24a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to execute:  0:02:11.944997\n"
     ]
    }
   ],
   "source": [
    "# Time the execution\n",
    "start_time = datetime.datetime.now()\n",
    "\n",
    "# Run the model\n",
    "response = run_model(prompt, tokenizer, model)\n",
    "\n",
    "#Print the length of time to run\n",
    "end_time = datetime.datetime.now()\n",
    "print(\"Time to execute: \", end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "984ba8ee-2efd-4557-a3af-76b5bddd0ecc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "894"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of tokens\n",
    "len(tokenizer.tokenize(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "04b38225-6385-4fba-9afe-cbea2bfa2a8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Okay, I need to analyze the financial statements of a company to predict the direction of future earnings. Let me go through the steps one by one.\n",
       "\n",
       "First, I'll look at the income statement. The revenue has been increasing over the past years: from 1.248940e+11 at t-5 to 1.416710e+11 at t. That's a positive sign. The cost of revenue is also increasing but not as fast as revenue, which is good because it means the gross profit is improving. Gross profit went from 3.177800e+10 at t-5 to 3.392300e+10 at t. \n",
       "\n",
       "Looking at operating expenses, they've been rising but not as much as revenue. Operating income increased from 4.986000e+9 at t-5 to 5.322000e+9 at t. Non-operating income had some fluctuations, but overall, the net income has been increasing, especially from t-3 to t, showing the company is getting more profitable.\n",
       "\n",
       "Now, the balance sheet. The company has a lot of cash, around 9.465000e+09 at t, which is good for liquidity. Accounts receivable and inventories are stable, but there's a significant amount in other short-term assets and property, plant, and equipment. The total current assets are solid, and the noncurrent assets are also increasing, which shows growth.\n",
       "\n",
       "Looking at liabilities, the current liabilities are quite high, especially payables and short-term debt. However, the company's current assets are covering these liabilities, so liquidity shouldn't be a problem. The long-term debt is also increasing, which might be a concern for leverage but seems manageable given the assets.\n",
       "\n",
       "Now, calculating the financial ratios. Profitability: gross margin is improving, which is good. Operating margin is stable, and net profit margin is increasing, indicating better profitability. Leverage ratio (debt-to-equity) is around 2, which is moderate. Liquidity ratios like current and quick ratios are healthy, meaning the company can cover its short-term obligations. Efficiency ratios like inventory turnover are stable, and asset turnover is improving, showing better use of assets.\n",
       "\n",
       "Interpreting these ratios: the company is profitable, has good liquidity, and is managing its assets efficiently. The increasing net income and improving margins suggest that future earnings are likely to increase. The company's ability to manage its costs and increase revenue without over-leveraging supports this prediction.\n",
       "\n",
       "So, I think the earnings will increase, and the magnitude is large because of the consistent growth in revenue and profitability over the past years.\n",
       "</think>\n",
       "\n",
       "To predict the direction of future earnings, we analyze the company's financial health through key ratios:\n",
       "\n",
       "1. **Profitability Ratios**:\n",
       "   - **Gross Margin**: Improved from 23.7% to 24.0%, indicating better cost control.\n",
       "   - **Operating Margin**: Stable at ~4.5%, showing consistent operational efficiency.\n",
       "   - **Net Profit Margin**: Increased from 2.7% to 2.9%, reflecting improved profitability.\n",
       "\n",
       "2. **Leverage Ratios**:\n",
       "   - **Debt-to-Equity Ratio**: ~2.0, moderate leverage, indicating a balance between debt and equity financing.\n",
       "\n",
       "3. **Liquidity Ratios**:\n",
       "   - **Current Ratio**: ~1.6, healthy liquidity to cover short-term liabilities.\n",
       "   - **Quick Ratio**: ~1.2, sufficient short-term assets to meet obligations.\n",
       "\n",
       "4. **Efficiency Ratios**:\n",
       "   - **Inventory Turnover**: ~3.0, stable inventory management.\n",
       "   - **Asset Turnover**: ~0.6, improving use of assets to generate revenue.\n",
       "\n",
       "**Conclusion**: The company's improving profitability, moderate leverage, strong liquidity, and efficient asset management suggest future earnings will **INCREASE** with a **LARGE** magnitude.\n",
       "\n",
       "```json\n",
       "{\n",
       "  \"earnings\": \"INCREASE\",\n",
       "  \"magnitude\": \"LARGE\"\n",
       "}\n",
       "```\n",
       "\n",
       "**Rationale**: The company demonstrates consistent revenue growth, improving profitability margins, and effective management of assets and liabilities. These factors support a prediction of a large increase in future earnings."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4396aaf6-8bc5-40e3-8b66-d740b9499d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_json(llm_output):\n",
    "    form = llm_output.replace('\\n','')\n",
    "    # Find the start and end of the JSON input\n",
    "    soj = form.find('```json')\n",
    "    eoj = form.find('}```')\n",
    "    # Pull out the additional context\n",
    "    additional = form[:soj]\n",
    "    additional += form[eoj + 4:]\n",
    "    json_obj = json.loads(form[soj + 7:eoj + 1])\n",
    "    json_obj['AdditionalContext'] = additional\n",
    "    return json_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "13805876-d894-4fa7-9256-245ba9a6fdbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Okay, so I'm trying to analyze the financial statements of a company to predict the direction of future earnings. I'm a bit new to this, so I need to break it down step by step. Let me start by understanding the data provided.\\n\\nFirst, the income statement has several items over the past five years. I notice that revenue has been fluctuating but seems to be decreasing slightly from t-1 to t. Other operating income is also decreasing, which might indicate that the company is earning less from non-core activities. Operating expenses are going down as well, which is a positive sign because it means the company is controlling its costs. However, the operating income or losses are also decreasing, which is concerning because it shows that the company's profitability from operations is declining.\\n\\nLooking at the balance sheet, the company has a lot of cash and short-term investments, which is good for liquidity. However, long-term investments and receivables are increasing, which could mean the company is investing more for the future, but it also ties up capital. Accounts payable is increasing, which might indicate that the company is taking on more short-term liabilities, possibly to fund operations or investments.\\n\\nNow, I need to compute key financial ratios. Let's start with profitability ratios. Net profit margin is net income divided by revenue. Looking at the data, net income available to common shareholders is decreasing from t-1 to t, while revenue is also decreasing. I need to calculate the actual numbers to see if the margin is improving or worsening.\\n\\nReturn on Assets (ROA) is net income divided by total assets. If assets are increasing but net income is decreasing, ROA might be declining, indicating less efficient use of assets. Return on Equity (ROE) is net income divided by equity. If equity is increasing but net income is decreasing, ROE might also be declining, which isn't good for shareholders.\\n\\nFor leverage ratios, debt-to-equity ratio is total liabilities divided by equity. If liabilities are increasing relative to equity, the company is becoming more leveraged, which could be risky. Interest coverage ratio is EBIT divided by interest expense. If EBIT is decreasing, this ratio might be falling, indicating the company is less able to cover interest payments.\\n\\nLiquidity ratios: Current ratio is current assets divided by current liabilities. The company's current assets are high, but current liabilities are zero in the latest period, which might be a mistake or an anomaly. Quick ratio is (cash + marketable securities + accounts receivable) divided by current liabilities. Again, with current liabilities at zero, this might not be meaningful.\\n\\nEfficiency ratios: Inventory turnover is cost of goods sold divided by average inventory. But I don't see inventory data here. Receivables turnover is revenue divided by accounts receivable. If accounts receivable is increasing while revenue is decreasing, this ratio might be falling, indicating slower collection of receivables. Asset turnover is revenue divided by total assets. If revenue is decreasing and assets are increasing, this ratio would decline, showing less efficient asset use.\\n\\nInterpreting these ratios, it seems the company's profitability is declining, possibly due to higher expenses or lower revenue. The company is taking on more debt, which increases leverage but might not be generating enough returns to justify it. Liquidity seems strong, but efficiency in asset management is worsening.\\n\\nPutting it all together, the company's earnings are likely to decrease in the future. The magnitude might be small because while profitability is declining, the company still has strong cash reserves, which could help mitigate some risks. However, the trend in revenue and operating income suggests a cautious outlook.\\n</think>\\n\\n**Analysis of Company Financial Statements**\\n\\n**1. Overview of Financial Health:**\\nThe company's financial health is characterized by fluctuating revenue and decreasing profitability. Key indicators such as net income and operating income are declining, suggesting a potential downturn in profitability. However, the company maintains strong liquidity with substantial cash reserves, which provides a buffer against financial risks.\\n\\n**2. Key Financial Ratios:**\\n\\n- **Profitability Ratios:**\\n  - **Net Profit Margin:** Decreasing trend due to lower net income and revenue.\\n  - **ROA (Return on Assets):** Declining, indicating less efficient asset utilization.\\n  - **ROE (Return on Equity):** Also declining, reflecting reduced returns for shareholders.\\n\\n- **Leverage Ratios:**\\n  - **Debt-to-Equity Ratio:** Increasing, suggesting higher leverage and potential financial risk.\\n  - **Interest Coverage Ratio:** Falling, indicating reduced capacity to cover interest expenses.\\n\\n- **Liquidity Ratios:**\\n  - **Current Ratio:** High due to significant current assets, though current liabilities are zero in the latest period, possibly an anomaly.\\n  - **Quick Ratio:** Not meaningful due to zero current liabilities.\\n\\n- **Efficiency Ratios:**\\n  - **Receivables Turnover:** Declining, showing slower collections.\\n  - **Asset Turnover:** Decreasing, indicating less efficient asset use.\\n\\n**3. Interpretation:**\\nThe company is experiencing declining profitability and efficiency, with increasing leverage. Despite strong liquidity, the trends suggest a cautious outlook.\\n\\n**4. Prediction:**\\n{'earnings': 'DECREASE', 'magnitude': 'SMALL'}\\n\\n**5. Rational:**\\nThe company's earnings are predicted to decrease moderately due to declining profitability and efficiency, though strong cash reserves may mitigate the impact. The increase in leverage adds risk, supporting a cautious outlook on future earnings.\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "45302cbe-908d-4753-aed6-390d1e2d513e",
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mformat_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[21], line 9\u001b[0m, in \u001b[0;36mformat_json\u001b[0;34m(llm_output)\u001b[0m\n\u001b[1;32m      7\u001b[0m additional \u001b[38;5;241m=\u001b[39m form[:soj]\n\u001b[1;32m      8\u001b[0m additional \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m form[eoj \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m4\u001b[39m:]\n\u001b[0;32m----> 9\u001b[0m json_obj \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mform\u001b[49m\u001b[43m[\u001b[49m\u001b[43msoj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43meoj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m json_obj[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAdditionalContext\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m additional\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m json_obj\n",
      "File \u001b[0;32m/opt/kernel/lib/python3.11/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[0;32m/opt/kernel/lib/python3.11/json/decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[1;32m    333\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[0;32m/opt/kernel/lib/python3.11/json/decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscan_once(s, idx)\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "format_json(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457537ec-fb2b-4bba-8181-0eae4bdb92b4",
   "metadata": {},
   "source": [
    "## Run the backtest and generate all responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eea06af1-1e6f-43e6-9874-6e27ce8e1d1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'company_data' from '/project/company_data.py'>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(s3Helpers)\n",
    "importlib.reload(company_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "beeb6302-6ecf-483a-a191-67a49296cfdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = s3Helpers.Logger('tmp/fs')\n",
    "def run_backtest(company_info, tokenizer, model, logger, log_at=50, start_count=0):\n",
    "    # start the timer\n",
    "    start_time = datetime.datetime.now()\n",
    "    # get the dates\n",
    "    dates = company_info.get_dates()\n",
    "    # set the current date year\n",
    "    current_year = dates[0][:4]\n",
    "\n",
    "    # set the array\n",
    "    year_log = []\n",
    "    \n",
    "    # set up the display\n",
    "    max_count = company_info.total_securities_in_backtest()\n",
    "    f = IntProgress(min=0, max=max_count) # instantiate the bar\n",
    "    l = Label(value=str(f.value))\n",
    "    display(HBox([f,l]))\n",
    "    \n",
    "    count = 0\n",
    "\n",
    "    # run the backtest \n",
    "    for date in dates:\n",
    "        \n",
    "        securities = company_info.get_securities_reporting_on_date(date)\n",
    "\n",
    "        for security in securities:\n",
    "            \n",
    "            # allow model to start running from a pre-set point\n",
    "            if count >= start_count:\n",
    "                \n",
    "                # Save to S3 every 50 interations to ensure there is a cache\n",
    "                if count % log_at == 0:\n",
    "                    # save the file to S3 and reset when it is a new year\n",
    "                    logger.log(year_log, current_year + str(count) + '.json')\n",
    "                    # reset the stats\n",
    "                    year_log = []\n",
    "                    current_year = date[:4]\n",
    "\n",
    "\n",
    "                prompt = company_info.get_prompt(date, security, system_prompt)\n",
    "                response = run_model(prompt, tokenizer, model)\n",
    "                try:\n",
    "                    formatted_response = format_json(response)\n",
    "                    formatted_response['security'] = security\n",
    "                    formatted_response['date'] = date\n",
    "                    year_log.append(formatted_response)\n",
    "                except:\n",
    "                    print(\"error with \" + security + date)\n",
    "                    error_json = {'security': security, 'date': date, 'response': response}\n",
    "                    year_log.append(error_json)\n",
    "                    \n",
    "            # Interate along the backtest\n",
    "            f.value += 1\n",
    "            count += 1\n",
    "            l.value = str(count) + \"/\" + str(max_count)\n",
    "    \n",
    "    # Log the last values\n",
    "    logger.log(year_log, current_year + str(count) + '.json')\n",
    "    # end the timer\n",
    "    end_time = datetime.datetime.now()\n",
    "    print(\"Completed! Time to execute: \", end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8c692788-ce72-43ca-8009-ac7249d0e917",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fcc597cd03949a1b1e6d601c6e2d8f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=896), Label(value='0')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://awmgd-prod-finml-sandbox-user/bclarke16/tmp/fs/logs/2020800.json\n",
      "Saved s3://awmgd-prod-finml-sandbox-user/bclarke16/tmp/fs/logs/2020800.json\n",
      "error with XOM UN Equity2024-08-02\n",
      "error with CVX UN Equity2024-08-02\n",
      "error with AMGN UW Equity2024-08-06\n",
      "error with NVDA UQ Equity2024-08-28\n",
      "error with AXP UN Equity2024-10-18\n",
      "error with SHW UN Equity2024-10-22\n",
      "error with IBM UN Equity2024-10-23\n",
      "error with KO UN Equity2024-10-23\n",
      "error with DOW UN Equity2024-10-25\n",
      "error with AMGN UQ Equity2024-10-30\n",
      "error with CAT UN Equity2024-10-30\n",
      "error with MSFT UW Equity2024-10-30\n",
      "s3://awmgd-prod-finml-sandbox-user/bclarke16/tmp/fs/logs/2024850.json\n",
      "Saved s3://awmgd-prod-finml-sandbox-user/bclarke16/tmp/fs/logs/2024850.json\n",
      "error with INTC UW Equity2024-10-31\n",
      "error with CSCO UW Equity2024-11-13\n",
      "error with CSCO UQ Equity2024-11-13\n",
      "error with HD UN Equity2024-11-19\n",
      "error with NVDA UQ Equity2024-11-20\n",
      "error with JPM UN Equity2025-01-15\n",
      "error with MSFT UW Equity2025-01-29\n",
      "error with AAPL UQ Equity2025-01-30\n",
      "error with INTC UQ Equity2025-01-30\n",
      "error with AAPL UW Equity2025-01-31\n",
      "error with MRK UN Equity2025-02-04\n",
      "error with AMGN UW Equity2025-02-04\n",
      "s3://awmgd-prod-finml-sandbox-user/bclarke16/tmp/fs/logs/2024896.json\n",
      "Saved s3://awmgd-prod-finml-sandbox-user/bclarke16/tmp/fs/logs/2024896.json\n",
      "Completed! Time to execute:  2:40:45.779705\n"
     ]
    }
   ],
   "source": [
    "run_backtest(sec_helper, tokenizer, model, logger, 50, 800)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d54639-2bf0-4ee5-b28c-51067a50360e",
   "metadata": {},
   "source": [
    "### Concatenate all of the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "64b057d5-eb29-447e-ae65-cb23046ae4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = s3Helpers.Logger('tmp/fs')\n",
    "log_list = logger.get_list_of_logs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0045bda3-133e-4654-bfda-ebae2f39e4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "logs = logger.create_master_log(save_to_s3=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "bbc0f159-f6d1-4063-bc62-f4ce98759148",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_all_logs():\n",
    "    log_list = logger.get_list_of_logs()\n",
    "    logs = []\n",
    "    for logfile in log_list:\n",
    "        logs += logger.get_log(logfile[logfile.find('/logs/') + 6:])\n",
    "    return logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "3ed3b7a7-8293-4b44-b58f-f7fd8ca30a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "logs = concat_all_logs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "37b4fdad-d6a0-45c5-98fa-d5cd85bf745d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "909"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6a0bdb21-17b9-4b00-b6fd-2db26070b33e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "800"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(logs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d300bff-276f-445b-b98e-a3810e8d591f",
   "metadata": {},
   "source": [
    "## Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43a03512-c413-4531-83c2-e254da5c54a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_helper = S3ModelHelper('tmp/fs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e31bc5a8-5917-487d-a7d2-74253b928027",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained('Data/DeepSeek14Q')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8c42064-7f5d-4f48-a388-ca8885e7131c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "model_helper.save_model_to_s3('Data/DeepSeek14Q','deepseek14Q')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44cf95f6-3187-47a5-9a75-6cef2dcaafba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_helper.clear_folder('Data/DeepSeek14Q')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "da415c52-15fc-4bd8-8917-805093786f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_json = [{'test':'test'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "968fe09b-51a7-4140-be96-b5e122aa594d",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.log(test_json, 'test.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "632f5d0d-e6c6-4260-84ba-2e0c965aa4b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bclarke16/tmp/fs/logs/20200.json',\n",
       " 'bclarke16/tmp/fs/logs/2020100.json',\n",
       " 'bclarke16/tmp/fs/logs/2020150.json',\n",
       " 'bclarke16/tmp/fs/logs/2020200.json',\n",
       " 'bclarke16/tmp/fs/logs/202050.json',\n",
       " 'bclarke16/tmp/fs/logs/2020800.json',\n",
       " 'bclarke16/tmp/fs/logs/2021250.json',\n",
       " 'bclarke16/tmp/fs/logs/2021300.json',\n",
       " 'bclarke16/tmp/fs/logs/2021350.json',\n",
       " 'bclarke16/tmp/fs/logs/2022400.json',\n",
       " 'bclarke16/tmp/fs/logs/2022450.json',\n",
       " 'bclarke16/tmp/fs/logs/2022500.json',\n",
       " 'bclarke16/tmp/fs/logs/2022550.json',\n",
       " 'bclarke16/tmp/fs/logs/2023600.json',\n",
       " 'bclarke16/tmp/fs/logs/2023650.json',\n",
       " 'bclarke16/tmp/fs/logs/2023700.json',\n",
       " 'bclarke16/tmp/fs/logs/2024750.json',\n",
       " 'bclarke16/tmp/fs/logs/2024800.json',\n",
       " 'bclarke16/tmp/fs/logs/2024850.json',\n",
       " 'bclarke16/tmp/fs/logs/2024896.json']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logger.get_list_of_logs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "94789e89-fe94-4060-aca1-5a0b23550c00",
   "metadata": {},
   "outputs": [],
   "source": [
    " d = logger.get_log('202010.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "3bf67b18-e45d-4b2d-80b7-c74901a168d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6508b723-ead0-49f3-b82b-e08f0303188a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sec_helper.get_security_statement('2020-01-31','AON UN Equity','is')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2e7b8120-2def-4fbd-84b8-6cd583928cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Data/base_deepseek_r2.json', 'w') as file:\n",
    "    json.dump(logs, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ee8fba-2085-45d2-8fd9-9dc4d39299c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_time = datetime.datetime.now()\n",
    "# #formatted_chat = tokenizer.apply_chat_template(prompt, tokenize=False, add_generation_prompt=True)\n",
    "# outputs = pipeline(\n",
    "#     prompt,\n",
    "#     max_new_tokens=1000,\n",
    "# )\n",
    "# end_time = datetime.datetime.now()\n",
    "# print(\"Time to execute: \", end_time - start_time)\n",
    "\n",
    "# test_output = outputs[0]['generated_text'][-1]\n",
    "# display(Markdown(test_output['content']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bloomberg Lab Python 3",
   "language": "python",
   "name": "remote-jupyterpython"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
