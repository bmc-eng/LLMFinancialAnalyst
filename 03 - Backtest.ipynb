{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de3912eb-612a-499e-9c4e-edee06488a45",
   "metadata": {},
   "source": [
    "# Backtest the strategies\n",
    "\n",
    "Use an LLM to go through and predict the buy/ sell/ hold recommendation for the company for the given date. Steps needed:\n",
    "\n",
    "1. Load the LLM - use DeepSeek R1 Qwen model at 7B parameters first and try the quantised models next\n",
    "2. Step through each data and each financial statement to get a result\n",
    "3. Log the results in a file and save to S3 (will need a logging file to save to S3 and resume in case of kernel crash)\n",
    "4. Need a backtesting framework to apply the results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d93b98-69cc-4462-a0f4-a17f2f95dd3f",
   "metadata": {},
   "source": [
    "## Load libraries needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3af882af-086b-45c8-a773-215a83e2a864",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "from s3fs import S3FileSystem\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from huggingface_hub import login\n",
    "import torch\n",
    "from accelerate import Accelerator\n",
    "\n",
    "import pandas as pd\n",
    "from IPython.display import Markdown, display\n",
    "from ipywidgets import IntProgress, Label, HBox\n",
    "\n",
    "from helper import get_s3_folder\n",
    "import s3Helpers\n",
    "import company_data\n",
    "from s3Helpers import S3ModelHelper, Logger\n",
    "from prompts import SYSTEM_PROMPTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4fb4ed3-be43-40fa-bd65-13d7588c9c3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 's3Helpers' from '/project/s3Helpers.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(company_data)\n",
    "importlib.reload(s3Helpers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb94ecb-4b18-41c5-8849-696b395f4de1",
   "metadata": {},
   "source": [
    "## Load the LLM\n",
    "\n",
    "Models to test:\n",
    "- Qwen (Qwen/Qwen2.5-7B-Instruct)\n",
    "- Llama (meta-llama/Llama-3.2-7B-Instruct)\n",
    "- DeepSeek (deepseek-ai/DeepSeek-R1-Distill-Qwen-14B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd948d2f-1791-4313-bedc-f9ed31aa63a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log into Huggingface\n",
    "\n",
    "with open('pass.txt') as p:\n",
    "    hf_login = p.read()\n",
    "    \n",
    "hf_login = hf_login[hf_login.find('=')+1:hf_login.find('\\n')]\n",
    "login(hf_login, add_to_git_credential=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4aaea478-b1ed-420b-bd8f-0851b1c6e3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Quantization \n",
    "quant_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    bnb_4bit_quant_type=\"nf4\"\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ab36cbb0-6764-4b22-b83d-7ff24b4aa054",
   "metadata": {},
   "outputs": [],
   "source": [
    "accelerator = Accelerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c2bb562-aec7-44a3-87a7-c509839c6dc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ce772870ade4e22aaf2f0c1373c6929",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73a0649eecda4e66859521c373749d34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/3.07k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36ceb21957df4953982531c182dde893",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/7.03M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Flag to download from Huggingface again or use stored model\n",
    "USE_HF = False\n",
    "USE_QUANTIZATION = False\n",
    "\n",
    "model_id = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-14B\"\n",
    "model_id_s3 = 'deepseek'\n",
    "\n",
    "\n",
    "if USE_HF:\n",
    "   \n",
    "    pipeline = transformers.pipeline(\n",
    "        \"text-generation\",\n",
    "        model=model_id,\n",
    "        model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
    "        device_map=\"auto\",\n",
    "    )\n",
    "    \n",
    "    if USE_QUANTIZATION:\n",
    "        model = AutoModelForCausalLM.from_pretrained(model_id, device_map='auto', quantization_config=quant_config)\n",
    "    else:\n",
    "        model = AutoModelForCausalLM.from_pretrained(model_id, device_map='auto', torch_dtype=torch.bfloat16)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "else:\n",
    "    model_helper = s3Helpers.S3ModelHelper(s3_sub_folder='tmp/fs')\n",
    "    if USE_QUANTIZATION:\n",
    "        model = model_helper.load_model(model_id_s3, quant_config)\n",
    "    else:\n",
    "        model = model_helper.load_model(model_id_s3)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "    pipeline = transformers.pipeline(\n",
    "        \"text-generation\",\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
    "        device_map=\"auto\",\n",
    "    )\n",
    "    model_helper.clear_folder(model_id_s3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6029e0fb-a198-4dea-b42b-d506c783a7f4",
   "metadata": {},
   "source": [
    "## Load Financial PIT dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eaa01423-1a10-4b83-a25c-ebf18b932470",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load from S3 using the helper file\n",
    "filename = 'data_quarterly_pit_indu.json'\n",
    "sec_helper = company_data.SecurityData('tmp/fs',filename)\n",
    "all_data = sec_helper.get_all_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "407bc769-45aa-44b4-96c8-24d14ca19040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# USE WHILE DEVELOPING to\n",
    "importlib.reload(company_data)\n",
    "sec_helper = company_data.SecurityData('tmp/fs',filename, all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e386e4c6-a489-46f2-b023-f58fb4313728",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "896"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sec_helper.total_securities_in_backtest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08ad27ae-6370-4efd-a9a2-185c13992ea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-04-24</th>\n",
       "      <td>114.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-24</th>\n",
       "      <td>119.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-24</th>\n",
       "      <td>124.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-24</th>\n",
       "      <td>127.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-08-24</th>\n",
       "      <td>117.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-09-24</th>\n",
       "      <td>118.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-24</th>\n",
       "      <td>116.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-24</th>\n",
       "      <td>119.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-24</th>\n",
       "      <td>124.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-24</th>\n",
       "      <td>135.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-24</th>\n",
       "      <td>128.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-24</th>\n",
       "      <td>84.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-24</th>\n",
       "      <td>83.17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Price\n",
       "Date              \n",
       "2019-04-24  114.02\n",
       "2019-05-24  119.51\n",
       "2019-06-24  124.14\n",
       "2019-07-24  127.95\n",
       "2019-08-24  117.76\n",
       "2019-09-24  118.17\n",
       "2019-10-24  116.41\n",
       "2019-11-24  119.06\n",
       "2019-12-24  124.74\n",
       "2020-01-24  135.11\n",
       "2020-02-24  128.19\n",
       "2020-03-24   84.05\n",
       "2020-04-24   83.17"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sec_helper.get_security_statement('2020-04-24','AXP UN Equity','px') #AXP UN Equity2020-04-24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0a5016b-31ec-4365-aef4-c8db0c063c0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You are a financial analyst and must make a buy, sell or hold decision on a company based only on the provided datasets.         Compute common financial ratios and then determine the buy or sell decision. Explain your reasons in less than 250 words. Provide a         confidence score for how confident you are of the decision. If you are not confident then lower the confidence score.         Your answer must be in a JSON object. Provide your answer in JSON format like the two examples below:         {'decision': BUY, 'confidence score': 80, 'reason': 'Gross profit and EPS have both increased over time'}         {'decision': SELL, 'confidence score': 90, 'reason': 'Price has declined and EPS is falling'}\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_prompt = SYSTEM_PROMPTS['BASE']['prompt']\n",
    "system_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eaed3958-56ad-43ca-92e1-17b6c3698e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = sec_helper.get_prompt('2020-04-24','AXP UN Equity', system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc4ce7f3-45c8-4cd3-89fc-92044d7a9e60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4218"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = tokenizer.apply_chat_template(prompt, tokenize=True, add_generation_prompt=True)\n",
    "len(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30342446-1709-4731-bb97-37a1a94dd62a",
   "metadata": {},
   "source": [
    "## Run an example in LLM\n",
    "\n",
    "Run into out of memory problem - Potential fixes:\n",
    "1. reduce size of model (quantize)\n",
    "2. explore multi-gpu\n",
    "3. reduce tokens\n",
    "\n",
    "https://saturncloud.io/blog/how-to-solve-cuda-out-of-memory-error-in-pytorch/\n",
    "\n",
    "https://huggingface.co/docs/accelerate/usage_guides/distributed_inference\n",
    "\n",
    "https://medium.com/@geronimo7/llms-multi-gpu-inference-with-accelerate-5a8333e4c5db\n",
    "\n",
    "Problem with splitting a single prompt into multiple gpus to calculate the result. Tensor parallelism - https://huggingface.co/docs/transformers/main/en/perf_train_gpu_many#tensor-parallelism\n",
    "\n",
    "nvidia-smi will show available GPUs on the system.\n",
    "\n",
    "### Run 1\n",
    "Model used: Llama 3.2 3B Instruct (meta-llama/Llama-3.2-3B-Instruct) \n",
    "No quantisation. Run in 5.5 hours on 1 A10G GPU on 896 security/ date combinations. The data is stored in log files in the project for further analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d04287fc-33e1-4934-8647-80000236de97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(prompt, tokenizer, model):\n",
    "    tokens = tokenizer.apply_chat_template(prompt, tokenize=False, add_generation_prompt=True)\n",
    "    model_inputs = tokenizer([tokens], return_tensors='pt').to('cuda')\n",
    "    generated_ids = model.generate(**model_inputs, pad_token_id=tokenizer.eos_token_id, max_new_tokens=1000)\n",
    "    parsed_ids = [\n",
    "        output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "    ]\n",
    "    return tokenizer.batch_decode(parsed_ids, skip_special_tokens=True)[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cad81f0d-e28a-4c9e-9380-6b4d09b9b24a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to execute:  0:01:02.676151\n"
     ]
    }
   ],
   "source": [
    "# Time the execution\n",
    "start_time = datetime.datetime.now()\n",
    "\n",
    "# Run the model\n",
    "response = run_model(prompt, tokenizer, model)\n",
    "\n",
    "#Print the length of time to run\n",
    "end_time = datetime.datetime.now()\n",
    "print(\"Time to execute: \", end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04b38225-6385-4fba-9afe-cbea2bfa2a8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Okay, I need to make a buy, sell, or hold decision based on the provided datasets. Let's start by looking at the income statement. The revenue has fluctuated over the years but hasn't shown a clear upward trend. It went from 1.1026e+10 to 1.1308e+10, then dropped and fluctuated. That's a bit concerning.\n",
       "\n",
       "Looking at the operating income or losses, I see it increased from t-5 to t-4 but then decreased in t-3 and t. It's 4.52e8 in t, which is lower than the previous year. That might indicate some issues with profitability.\n",
       "\n",
       "The EPS has been fluctuating as well. In t, it's 0.41, which is lower than the previous years. That's a red flag because lower EPS can mean the company is earning less per share, which might not be attractive to investors.\n",
       "\n",
       "Moving to the balance sheet, the cash and cash equivalents have been fluctuating. In t, it's 3.6095e10, which is lower than t-1. While they have significant cash, the decrease might indicate they're spending more or not generating as much cash.\n",
       "\n",
       "Looking at liabilities, the total noncurrent liabilities have been increasing. From t-5 to t, they've gone up from 8.0997e10 to 7.5618e10, but wait, actually, in t, it's 7.5618e10, which is lower than t-1's 8.2783e10. Hmm, maybe that's not too bad. But overall, the company has a high amount of debt, which could be risky.\n",
       "\n",
       "The price history shows some volatility. From 2019 to 2020, the price peaked at 135.11 but then dropped to 84.05 and 83.17. That's a significant drop, which might indicate investor loss of confidence or market issues.\n",
       "\n",
       "Considering all these factors: fluctuating revenue, decreasing operating income, lower EPS, high debt, and volatile stock price. These are all negative signs. The company isn't performing as strongly as it could be, and the stock has shown recent weakness. I'm leaning towards a sell decision because the fundamentals aren't strong, and the stock price might continue to drop.\n",
       "\n",
       "I'm about 75% confident in this decision because while there are some positive aspects like cash on hand, the negatives like decreasing profits and EPS are more concerning. Plus, the stock price has shown significant drops recently, which could be a sign of further decline.\n",
       "</think>\n",
       "\n",
       "```json\n",
       "{\n",
       "  \"decision\": \"SELL\",\n",
       "  \"confidence score\": 75,\n",
       "  \"reason\": \"Revenue and operating income have fluctuated, EPS has decreased, and the stock price has shown recent weakness and volatility.\"\n",
       "}\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4396aaf6-8bc5-40e3-8b66-d740b9499d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_json(llm_output):\n",
    "    form = llm_output.replace('\\n','')\n",
    "    # Find the start and end of the JSON input\n",
    "    soj = form.find('```json')\n",
    "    eoj = form.find('}```')\n",
    "    # Pull out the additional context\n",
    "    additional = form[:soj]\n",
    "    additional += form[eoj + 4:]\n",
    "    json_obj = json.loads(form[soj + 7:eoj + 1])\n",
    "    json_obj['AdditionalContext'] = additional\n",
    "    return json_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "13805876-d894-4fa7-9256-245ba9a6fdbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Okay, I need to make a buy, sell, or hold decision based on the provided datasets. Let\\'s start by looking at the income statement. The revenue has fluctuated over the years but hasn\\'t shown a clear upward trend. It went from 1.1026e+10 to 1.1308e+10, then dropped and fluctuated. That\\'s a bit concerning.\\n\\nLooking at the operating income or losses, I see it increased from t-5 to t-4 but then decreased in t-3 and t. It\\'s 4.52e8 in t, which is lower than the previous year. That might indicate some issues with profitability.\\n\\nThe EPS has been fluctuating as well. In t, it\\'s 0.41, which is lower than the previous years. That\\'s a red flag because lower EPS can mean the company is earning less per share, which might not be attractive to investors.\\n\\nMoving to the balance sheet, the cash and cash equivalents have been fluctuating. In t, it\\'s 3.6095e10, which is lower than t-1. While they have significant cash, the decrease might indicate they\\'re spending more or not generating as much cash.\\n\\nLooking at liabilities, the total noncurrent liabilities have been increasing. From t-5 to t, they\\'ve gone up from 8.0997e10 to 7.5618e10, but wait, actually, in t, it\\'s 7.5618e10, which is lower than t-1\\'s 8.2783e10. Hmm, maybe that\\'s not too bad. But overall, the company has a high amount of debt, which could be risky.\\n\\nThe price history shows some volatility. From 2019 to 2020, the price peaked at 135.11 but then dropped to 84.05 and 83.17. That\\'s a significant drop, which might indicate investor loss of confidence or market issues.\\n\\nConsidering all these factors: fluctuating revenue, decreasing operating income, lower EPS, high debt, and volatile stock price. These are all negative signs. The company isn\\'t performing as strongly as it could be, and the stock has shown recent weakness. I\\'m leaning towards a sell decision because the fundamentals aren\\'t strong, and the stock price might continue to drop.\\n\\nI\\'m about 75% confident in this decision because while there are some positive aspects like cash on hand, the negatives like decreasing profits and EPS are more concerning. Plus, the stock price has shown significant drops recently, which could be a sign of further decline.\\n</think>\\n\\n```json\\n{\\n  \"decision\": \"SELL\",\\n  \"confidence score\": 75,\\n  \"reason\": \"Revenue and operating income have fluctuated, EPS has decreased, and the stock price has shown recent weakness and volatility.\"\\n}\\n```'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "45302cbe-908d-4753-aed6-390d1e2d513e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'decision': 'SELL',\n",
       " 'confidence score': 75,\n",
       " 'reason': 'Revenue and operating income have fluctuated, EPS has decreased, and the stock price has shown recent weakness and volatility.',\n",
       " 'AdditionalContext': \"Okay, I need to make a buy, sell, or hold decision based on the provided datasets. Let's start by looking at the income statement. The revenue has fluctuated over the years but hasn't shown a clear upward trend. It went from 1.1026e+10 to 1.1308e+10, then dropped and fluctuated. That's a bit concerning.Looking at the operating income or losses, I see it increased from t-5 to t-4 but then decreased in t-3 and t. It's 4.52e8 in t, which is lower than the previous year. That might indicate some issues with profitability.The EPS has been fluctuating as well. In t, it's 0.41, which is lower than the previous years. That's a red flag because lower EPS can mean the company is earning less per share, which might not be attractive to investors.Moving to the balance sheet, the cash and cash equivalents have been fluctuating. In t, it's 3.6095e10, which is lower than t-1. While they have significant cash, the decrease might indicate they're spending more or not generating as much cash.Looking at liabilities, the total noncurrent liabilities have been increasing. From t-5 to t, they've gone up from 8.0997e10 to 7.5618e10, but wait, actually, in t, it's 7.5618e10, which is lower than t-1's 8.2783e10. Hmm, maybe that's not too bad. But overall, the company has a high amount of debt, which could be risky.The price history shows some volatility. From 2019 to 2020, the price peaked at 135.11 but then dropped to 84.05 and 83.17. That's a significant drop, which might indicate investor loss of confidence or market issues.Considering all these factors: fluctuating revenue, decreasing operating income, lower EPS, high debt, and volatile stock price. These are all negative signs. The company isn't performing as strongly as it could be, and the stock has shown recent weakness. I'm leaning towards a sell decision because the fundamentals aren't strong, and the stock price might continue to drop.I'm about 75% confident in this decision because while there are some positive aspects like cash on hand, the negatives like decreasing profits and EPS are more concerning. Plus, the stock price has shown significant drops recently, which could be a sign of further decline.</think>\"}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "format_json(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457537ec-fb2b-4bba-8181-0eae4bdb92b4",
   "metadata": {},
   "source": [
    "## Run the backtest and generate all responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "eea06af1-1e6f-43e6-9874-6e27ce8e1d1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'company_data' from '/project/company_data.py'>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(s3Helpers)\n",
    "importlib.reload(company_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "beeb6302-6ecf-483a-a191-67a49296cfdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = s3Helpers.Logger('tmp/fs')\n",
    "def run_backtest(company_info, tokenizer, model, logger, log_at=50, start_count=0):\n",
    "    # start the timer\n",
    "    start_time = datetime.datetime.now()\n",
    "    # get the dates\n",
    "    dates = company_info.get_dates()\n",
    "    # set the current date year\n",
    "    current_year = dates[0][:4]\n",
    "\n",
    "    # set the array\n",
    "    year_log = []\n",
    "    \n",
    "    # set up the display\n",
    "    max_count = company_info.total_securities_in_backtest()\n",
    "    f = IntProgress(min=0, max=max_count) # instantiate the bar\n",
    "    l = Label(value=str(f.value))\n",
    "    display(HBox([f,l]))\n",
    "    \n",
    "    count = 0\n",
    "\n",
    "    # run the backtest \n",
    "    for date in dates:\n",
    "        \n",
    "        securities = company_info.get_securities_reporting_on_date(date)\n",
    "\n",
    "        for security in securities:\n",
    "            \n",
    "            # allow model to start running from a pre-set point\n",
    "            if count >= start_count:\n",
    "                \n",
    "                # Save to S3 every 50 interations to ensure there is a cache\n",
    "                if count % log_at == 0:\n",
    "                    # save the file to S3 and reset when it is a new year\n",
    "                    logger.log(year_log, current_year + str(count) + '.json')\n",
    "                    # reset the stats\n",
    "                    year_log = []\n",
    "                    current_year = date[:4]\n",
    "\n",
    "\n",
    "                prompt = company_info.get_prompt(date, security, system_prompt)\n",
    "                response = run_model(prompt, tokenizer, model)\n",
    "                try:\n",
    "                    formatted_response = format_json(response)\n",
    "                    formatted_response['security'] = security\n",
    "                    formatted_response['date'] = date\n",
    "                    year_log.append(formatted_response)\n",
    "                except:\n",
    "                    print(\"error with \" + security + date)\n",
    "                    error_json = {'security': security, 'date': date, 'response': response}\n",
    "                    year_log.append(error_json)\n",
    "                    \n",
    "            # Interate along the backtest\n",
    "            f.value += 1\n",
    "            count += 1\n",
    "            l.value = str(count) + \"/\" + str(max_count)\n",
    "    \n",
    "    # Log the last values\n",
    "    logger.log(year_log, current_year + str(count) + '.json')\n",
    "    # end the timer\n",
    "    end_time = datetime.datetime.now()\n",
    "    print(\"Completed! Time to execute: \", end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "8c692788-ce72-43ca-8009-ac7249d0e917",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c01dd433a79347679c9a77e799443028",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=896), Label(value='0')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error with MMM UN Equity2025-01-21\n",
      "error with PG UN Equity2025-01-22\n",
      "error with TRV UN Equity2025-01-22\n",
      "error with AXP UN Equity2025-01-24\n",
      "error with RTX UN Equity2025-01-28\n",
      "error with BA UN Equity2025-01-28\n",
      "error with V UN Equity2025-01-30\n",
      "error with AAPL UQ Equity2025-01-30\n",
      "error with CAT UN Equity2025-01-30\n",
      "error with PFE UN Equity2025-02-04\n",
      "Saved 2020896.json\n"
     ]
    }
   ],
   "source": [
    "run_backtest(sec_helper, tokenizer, model, logger)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d54639-2bf0-4ee5-b28c-51067a50360e",
   "metadata": {},
   "source": [
    "### Concatenate all of the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "64b057d5-eb29-447e-ae65-cb23046ae4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_list = logger.get_list_of_logs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "ee7c034a-b3c4-4059-85c6-f3bbfa25d218",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20200.json'"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_list[0][log_list[0].find('/logs/') + 6:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "bbc0f159-f6d1-4063-bc62-f4ce98759148",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_all_logs():\n",
    "    log_list = logger.get_list_of_logs()\n",
    "    logs = []\n",
    "    for logfile in log_list:\n",
    "        logs += logger.get_log(logfile[logfile.find('/logs/') + 6:])\n",
    "    return logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "3ed3b7a7-8293-4b44-b58f-f7fd8ca30a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "logs = concat_all_logs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "37b4fdad-d6a0-45c5-98fa-d5cd85bf745d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "909"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "6a0bdb21-17b9-4b00-b6fd-2db26070b33e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06b383f-9349-4358-ac99-53ace3132520",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a03512-c413-4531-83c2-e254da5c54a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31bc5a8-5917-487d-a7d2-74253b928027",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "da415c52-15fc-4bd8-8917-805093786f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_json = [{'test':'test'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "968fe09b-51a7-4140-be96-b5e122aa594d",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.log(test_json, 'test.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "632f5d0d-e6c6-4260-84ba-2e0c965aa4b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bclarke16/tmp/fs/logs/20200.json',\n",
       " 'bclarke16/tmp/fs/logs/202010.json',\n",
       " 'bclarke16/tmp/fs/logs/test.json']"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logger.get_list_of_logs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "94789e89-fe94-4060-aca1-5a0b23550c00",
   "metadata": {},
   "outputs": [],
   "source": [
    " d = logger.get_log('202010.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "3bf67b18-e45d-4b2d-80b7-c74901a168d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6508b723-ead0-49f3-b82b-e08f0303188a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sec_helper.get_security_statement('2020-01-31','AON UN Equity','is')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "2e7b8120-2def-4fbd-84b8-6cd583928cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('Data/base2.json', 'w') as file:\n",
    "#    json.dump(logs, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ee8fba-2085-45d2-8fd9-9dc4d39299c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_time = datetime.datetime.now()\n",
    "# #formatted_chat = tokenizer.apply_chat_template(prompt, tokenize=False, add_generation_prompt=True)\n",
    "# outputs = pipeline(\n",
    "#     prompt,\n",
    "#     max_new_tokens=1000,\n",
    "# )\n",
    "# end_time = datetime.datetime.now()\n",
    "# print(\"Time to execute: \", end_time - start_time)\n",
    "\n",
    "# test_output = outputs[0]['generated_text'][-1]\n",
    "# display(Markdown(test_output['content']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BQuant Python 3",
   "language": "python",
   "name": "remote-jupyterpython"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
